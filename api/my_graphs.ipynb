{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya-ladawa/Aditya/z_projects/aireas/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started Qdrant client.\n",
      "Collection 'aireas-cloud' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9648/2803296740.py:132: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  qdrant_retriever_tool = qdrant_retriever.as_tool(\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, List, Optional, Union, Dict, Annotated, Literal\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage, trim_messages\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "# from team_tools import tavily_search_tool, arxiv_search_tool, web_scraper_tool, repl_tool\n",
    "from qdrant_cloud_ops import initialize_selfquery_retriever, qdrant_vector_store\n",
    "from llm_chains import decomposition_chain, requires_decomposition, rephrase_chain, get_plan_chain, assign_chat_topic, memory_decision_chain, check_knowledge_base_chain\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import re\n",
    "import functools\n",
    "import operator\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from token_counter import tiktoken_counter\n",
    "\n",
    "from team_tools import tavily_search_tool, arxiv_search_tool, repl_tool\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "llm = ChatGroq(model='llama-3.3-70b-versatile', temperature=1.0)\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"what is neural_networks.pdf talking about\",\n",
    "        {\n",
    "            \"query\": \"neural networks\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"neural_networks.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Can you tell me something about the file cancer_research_study.pdf?\",\n",
    "        {\n",
    "            \"query\": \"cancer research\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"cancer_research_study.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"I need to know what ethics_in_ai.pdf says on ethical concerns.\",\n",
    "        {\n",
    "            \"query\": \"ethical concerns\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"ethics_in_ai.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Find me anything related to quantum_computing_paper.pdf\",\n",
    "        {\n",
    "            \"query\": \"quantum computing\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"quantum_computing_paper.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Are there any references to Einstein's theories in physics_papers.pdf?\",\n",
    "        {\n",
    "            \"query\": \"Einstein's theories\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"physics_papers.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"What's in the climate_change_analysis.pdf about global warming?\",\n",
    "        {\n",
    "            \"query\": \"global warming\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"climate_change_analysis.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Show me papers discussing blockchain from blockchain_articles.pdf\",\n",
    "        {\n",
    "            \"query\": \"blockchain technology\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"blockchain_articles.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Can you retrieve sections of deep_learning_basics.pdf?\",\n",
    "        {\n",
    "            \"query\": \"deep learning\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"deep_learning_basics.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Who authored machine_learning_review.pdf and neural_network_overview.pdf?\",\n",
    "        {\n",
    "            \"query\": \"authors\",\n",
    "            \"filter\": 'or(eq(\"pdf_name\", \"machine_learning_review.pdf\"), eq(\"pdf_name\", \"neural_network_overview.pdf\"))',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Give me the details from data_analysis_guide.pdf\",\n",
    "        {\n",
    "            \"query\": \"data analysis\",\n",
    "            \"filter\": 'eq(\"pdf_name\", \"data_analysis_guide.pdf\")',\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=5984,\n",
    "    strategy=\"last\",\n",
    "    token_counter=tiktoken_counter,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "trimmer_first = trim_messages(\n",
    "    max_tokens=1500,\n",
    "    strategy=\"first\",\n",
    "    token_counter=tiktoken_counter,\n",
    "    # include_system=False,\n",
    "    allow_partial=True,\n",
    ")\n",
    "\n",
    "qdrant_retriever = initialize_selfquery_retriever(llm, qdrant_vector_store=qdrant_vector_store, examples=examples)\n",
    "qdrant_retriever_tool = qdrant_retriever.as_tool(\n",
    "    name=\"retrieve_research_paper_texts\",\n",
    "    description=\"Search and return information from the vector database containing texts of several research papers, and scholarly articles. optionally, align the search process based on pdf name (.pdf file) if given.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposer_chain = decomposition_chain(llm=llm)\n",
    "check_query_chain = requires_decomposition(llm=llm)\n",
    "rephraser_chain = rephrase_chain(llm=llm)\n",
    "planner_chain = get_plan_chain(llm=llm)\n",
    "assign_topic_chain = assign_chat_topic(llm=llm)\n",
    "check_knowledge_base = check_knowledge_base_chain(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(planner_chain.invoke({'task': \"explain depth first search and give the python code, also create a suumary report\", 'knowledge_chain_answer': 'Not-relevant', 'messages':[]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = create_react_agent(model=llm, tools=[tavily_search_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in k.stream({'messages': [HumanMessage(content='give some research papers on SVM')]}, stream_mode='values'):\n",
    "#   print(i['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = PostgresStore.from_conn_string(conn_string=\"postgresql://adi:root@localhost:5432/chat_store\")\n",
    "user_id = 'd36a9747-e419-4c20-b6ee-714be5fc3790'\n",
    "con_id = 'b653fa76-f021-413a-9b69-1fd561f31d07'\n",
    "conn_string = \"postgresql://adi:root@localhost:5432/chat_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_info(conn_string, user_id, con_id):\n",
    "    with PostgresStore.from_conn_string(conn_string=conn_string) as store:\n",
    "        # Search for metadata\n",
    "        conversation_metadata = store.search((\"conversation_metadata\", user_id, con_id))\n",
    "        \n",
    "        # Format metadata\n",
    "        metadata_info = \"\\n\".join(\n",
    "            f\"{item.key.replace('metadata_', '')} | \"\n",
    "            f\"{item.value.get('title', 'Unknown')} | \"\n",
    "            f\"{', '.join(item.value.get('authors', []))} | \"\n",
    "            f\"{item.value.get('description', 'Unknown')}\"\n",
    "            for item in conversation_metadata\n",
    "        )\n",
    "    return metadata_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResearchTeamState(TypedDict):\n",
    "#   messages: Annotated[List[BaseMessage], operator.add]    \n",
    "#   task: str\n",
    "#   plan_string: str\n",
    "#   steps: List\n",
    "#   results: dict\n",
    "#   result: str\n",
    "\n",
    "\n",
    "# def get_plan(state: ResearchTeamState) -> Command[Literal[\"agent_exec\"]]:\n",
    "#     try:\n",
    "#         regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "\n",
    "#         task = state['messages'][-1].content\n",
    "#         messages = state['messages']\n",
    "\n",
    "#         metadata_info = get_metadata_info(conn_string=conn_string, user_id=user_id, con_id=con_id)\n",
    "#         rag_guidance = check_knowledge_base.invoke({'query': task, 'data': metadata_info})\n",
    "#         plan = planner_chain.invoke({'task': task, 'knowledge_chain_answer': rag_guidance, 'messages': state['messages']})\n",
    "\n",
    "#         print(metadata_info, '\\n')\n",
    "#         print(rag_guidance, '\\n')\n",
    "\n",
    "#         print(plan, '\\n', f'{\"-\" * 56}', '\\n')\n",
    "\n",
    "#         matches = re.findall(regex_pattern, plan)\n",
    "#         return Command(update={\"steps\": matches, \"plan_string\": plan, 'task': task}, goto='agent_exec')\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error occurred: {e}\")\n",
    "#         return Command(update={\"steps\": [], \"plan_string\": \"\", 'task': ''}, goto=END)\n",
    "\n",
    "\n",
    "  \n",
    "# rag_agent = create_react_agent(llm, tools=[qdrant_retriever_tool])\n",
    "# search_agent = create_react_agent(llm, tools=[tavily_search_tool])\n",
    "# arxiv_agent = create_react_agent(llm, tools=[arxiv_search_tool])\n",
    "# code_agent = create_react_agent(llm, tools=[repl_tool])\n",
    "\n",
    "\n",
    "# def code_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Coder\")]}\n",
    "\n",
    "# def retriever_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Retriever\")]}\n",
    "\n",
    "# def search_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Searcher\")]}\n",
    "\n",
    "# def arxiv_search_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"ArXivSearcher\")]}\n",
    "\n",
    "\n",
    "# def _get_current_task(state: ResearchTeamState):\n",
    "#     if \"results\" not in state or state[\"results\"] is None:\n",
    "#         return 1\n",
    "#     if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "#         return None\n",
    "#     else:\n",
    "#         return len(state[\"results\"]) + 1\n",
    "\n",
    "\n",
    "\n",
    "# def agent_exec(state: ResearchTeamState):\n",
    "#     \"\"\"Worker node that executes the agents accordingly for a given plan.\"\"\"\n",
    "#     try:\n",
    "\n",
    "#         _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "#         _step = _get_current_task(state)\n",
    "#         step_desc, step_name, agent, agent_input = state[\"steps\"][_step - 1]\n",
    "\n",
    "#         # Replace placeholders in agent_input with corresponding results\n",
    "#         for k, v in _results.items():\n",
    "#             agent_input = agent_input.replace(k, v) \n",
    "\n",
    "#         # Dynamically select the agent function based on the agent name\n",
    "#         if agent == \"RagSearcher\":\n",
    "#             result = rag_agent.invoke(retriever_node(state))['messages'][-1].content\n",
    "#         elif agent == \"Searcher\":\n",
    "#             result = search_agent.invoke(search_node(state))['messages'][-1].content\n",
    "#         elif agent == \"ChatBot\":\n",
    "#             result = llm.invoke(agent_input)  # Assuming LLM invocation does not need message formatting\n",
    "#         elif agent == \"Coder\":\n",
    "#             result = code_agent.invoke(code_node(state))['messages'][-1].content\n",
    "#         elif agent == \"ArXivSearcher\":\n",
    "#             result = arxiv_agent.invoke(arxiv_search_node(state))['messages'][-1].content\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown agent type: {agent}\")\n",
    "\n",
    "#         if result is None:\n",
    "#             raise ValueError(f\"Agent {agent} did not return a result for step {step_name}\")\n",
    "\n",
    "#         # Store the result in the _results dictionary\n",
    "#         _results[step_name] = str(result)\n",
    "\n",
    "#         return {\"results\": _results}\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error occurred: {e}\")\n",
    "#         return Command(update={'plan_string': \"\", 'steps': [], 'results': {}, 'result': \"\"}, goto=END)\n",
    "\n",
    "# solve_prompt = \"\"\"\n",
    "# We have created a detailed step-by-step Plan to solve the given task and obtained corresponding answers from agents for each step in the Plan. \n",
    "# Use these agent-provided answers as Evidence to craft a clear, comprehensive, and cohesive response.\n",
    "\n",
    "# Plan:  \n",
    "# {plan}\n",
    "\n",
    "# Using the Evidence from the answers provided for each step in the Plan, solve the given task:  \n",
    "# Task: {task}\n",
    "\n",
    "# Provide your response below in a well-structured and coherent format:  \n",
    "# Response:\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# def solve(state: ResearchTeamState) -> Command[Literal[END]]:\n",
    "#     try:\n",
    "#         plan = \"\"\n",
    "#         for _plan, step_name, agent, agent_input in state[\"steps\"]:\n",
    "#             _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "#             for k, v in _results.items():\n",
    "#                 agent_input = agent_input.replace(k, v)\n",
    "#                 step_name = step_name.replace(k, v)\n",
    "#             plan += f\"Plan: {_plan}\\n{step_name} = {agent}[{agent_input}]\"\n",
    "        \n",
    "#         prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n",
    "#         result = llm.invoke(prompt)\n",
    "        \n",
    "#         return Command(\n",
    "#             update={\"result\": result.content, 'messages': [result], 'results': {}, 'steps': [], 'task': '', 'plan_string': ''},\n",
    "#             goto=END,\n",
    "#         )\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error occurred: {e}\")\n",
    "#         return Command(update={'task': '', 'plan_string': '', 'steps': [], 'results': {}, 'result': \"\"}, goto=END)\n",
    "\n",
    "\n",
    "# def _route(state):\n",
    "#     _step = _get_current_task(state)\n",
    "#     if _step is None:\n",
    "#         return \"solve\"\n",
    "#     else:\n",
    "#         return \"agent_exec\"\n",
    "\n",
    "\n",
    "# graph = StateGraph(ResearchTeamState)\n",
    "\n",
    "# # graph.add_node('decompose_or_rephrase', decompose_or_rephrase)\n",
    "# graph.add_node('get_plan', get_plan)\n",
    "# graph.add_node(\"agent_exec\", agent_exec)\n",
    "# graph.add_node(\"solve\", solve)\n",
    "\n",
    "# # # graph.add_edge(START, 'decompose_or_rephrase')\n",
    "# graph.add_edge(START, 'get_plan')\n",
    "# # # graph.add_edge('decompose_or_rephrase', 'get_plan')\n",
    "# # graph.add_edge('get_plan', 'agent_exec')\n",
    "# graph.add_conditional_edges(\"agent_exec\", _route)\n",
    "# # # graph.add_edge(\"solve\", END)\n",
    "\n",
    "# research_graph_compiled = graph.compile(checkpointer=memory)\n",
    "# research_graph = research_graph_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "# for s in research_graph.stream({'messages': [HumanMessage('can you explain or summarize first paper you gave?')]}, config=config):\n",
    "#   print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research_graph.get_state(config=config, subgraphs=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResearchTeamState(TypedDict):\n",
    "#   messages: Annotated[List[BaseMessage], operator.add]    \n",
    "#   task: str\n",
    "#   plan_string: str\n",
    "#   steps: List\n",
    "#   results: dict\n",
    "#   result: str\n",
    "\n",
    "# def decompose_or_rephrase(state: ResearchTeamState):\n",
    "#   question = state['messages'][-1].content\n",
    "#   task = None\n",
    "#   try:\n",
    "#       status = check_query_chain.invoke(question)\n",
    "\n",
    "#       if status == 'Decompose':\n",
    "#           task = decomposer_chain.invoke(question)\n",
    "#       elif status == 'Rephrase':\n",
    "#           task = rephraser_chain.invoke(question)\n",
    "#       else:\n",
    "#           raise ValueError(f\"Unexpected status from check_query_chain: {status}\")\n",
    "#   except Exception as e:\n",
    "#       raise RuntimeError(f\"Error during processing: {e}\")\n",
    "\n",
    "#   return {'task': task}\n",
    "\n",
    "\n",
    "# def get_plan(state: ResearchTeamState):\n",
    "#   regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "\n",
    "# #   task = state['task']\n",
    "#   task = state['messages'][-1].content\n",
    "#   messages = state['messages']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   metadata_info = get_metadata_info(conn_string=conn_string, user_id=user_id, con_id=con_id)\n",
    "\n",
    "\n",
    "#   rag_guidance = check_knowledge_base.invoke({'query': task, 'data': metadata_info})\n",
    "#   plan = planner_chain.invoke({'task': task, 'knowledge_chain_answer': rag_guidance, 'messages': state['messages']})\n",
    "#   print(plan, '\\n', f'{'-' * 56}')\n",
    "\n",
    "#   matches = re.findall(regex_pattern, plan)\n",
    "#   return {\"steps\": matches, \"plan\": plan, 'task': task}\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# rag_agent = create_react_agent(llm, tools=[qdrant_retriever_tool])\n",
    "# search_agent = create_react_agent(llm, tools=[tavily_search_tool])\n",
    "# arxiv_agent = create_react_agent(llm, tools=[arxiv_search_tool])\n",
    "# code_agent = create_react_agent(llm, tools=[repl_tool])\n",
    "\n",
    "\n",
    "# def code_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Coder\")]}\n",
    "\n",
    "# def retriever_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Retriever\")]}\n",
    "\n",
    "# def search_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Searcher\")]}\n",
    "\n",
    "# def arxiv_search_node(state: ResearchTeamState):\n",
    "#     return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"ArXivSearcher\")]}\n",
    "\n",
    "\n",
    "# def _get_current_task(state: ResearchTeamState):\n",
    "#     if \"results\" not in state or state[\"results\"] is None:\n",
    "#         return 1\n",
    "#     if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "#         return None\n",
    "#     else:\n",
    "#         return len(state[\"results\"]) + 1\n",
    "\n",
    "\n",
    "\n",
    "# def agent_exec(state: ResearchTeamState):\n",
    "#     \"\"\"Worker node that executes the agents accordingly for a given plan.\"\"\"\n",
    "\n",
    "#     _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "#     _step = _get_current_task(state)\n",
    "#     step_desc, step_name, agent, agent_input = state[\"steps\"][_step - 1]\n",
    "\n",
    "#     # Replace placeholders in agent_input with corresponding results\n",
    "#     for k, v in _results.items():\n",
    "#         agent_input = agent_input.replace(k, v) \n",
    "\n",
    "#     # Dynamically select the agent function based on the agent name\n",
    "#     if agent == \"RagSearcher\":\n",
    "#         result = rag_agent.invoke(retriever_node(state))['messages'][-1].content\n",
    "#     elif agent == \"Searcher\":\n",
    "#         result = search_agent.invoke(search_node(state))['messages'][-1].content\n",
    "#     elif agent == \"ChatBot\":\n",
    "#         result = llm.invoke(agent_input)  # Assuming LLM invocation does not need message formatting\n",
    "#     elif agent == \"Coder\":\n",
    "#         result = code_agent.invoke(code_node(state))['messages'][-1].content\n",
    "#     elif agent == \"ArXivSearcher\":\n",
    "#         result = arxiv_agent.invoke(arxiv_search_node(state))['messages'][-1].content\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown agent type: {agent}\")\n",
    "\n",
    "#     if result is None:\n",
    "#         raise ValueError(f\"Agent {agent} did not return a result for step {step_name}\")\n",
    "\n",
    "#     # Store the result in the _results dictionary\n",
    "#     _results[step_name] = str(result)\n",
    "\n",
    "#     return {\"results\": _results}\n",
    "\n",
    "# solve_prompt = \"\"\"\n",
    "# We have created a detailed step-by-step Plan to solve the given task and obtained corresponding answers from agents for each step in the Plan. \n",
    "# Use these agent-provided answers as Evidence to craft a clear, comprehensive, and cohesive response.\n",
    "\n",
    "# Plan:  \n",
    "# {plan}\n",
    "\n",
    "# Using the Evidence from the answers provided for each step in the Plan, solve the given task:  \n",
    "# Task: {task}\n",
    "\n",
    "# Provide your response below in a well-structured and coherent format:  \n",
    "# Response:\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# from langgraph.types import Command\n",
    "\n",
    "\n",
    "# def solve(state: ResearchTeamState) -> Command[Literal[END]]:\n",
    "#     plan = \"\"\n",
    "#     for _plan, step_name, agent, agent_input in state[\"steps\"]:\n",
    "#         _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "#         for k, v in _results.items():\n",
    "#             agent_input = agent_input.replace(k, v)\n",
    "#             step_name = step_name.replace(k, v)\n",
    "#         plan += f\"Plan: {_plan}\\n{step_name} = {agent}[{agent_input}]\"\n",
    "#     prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n",
    "#     result = llm.invoke(prompt)\n",
    "#     # return {\"result\": result.content, 'messages': [result]}\n",
    "#     return Command(\n",
    "#         update={\"result\": result.content, 'messages': [result], 'results': {}, 'steps': [], 'task': '', 'plan_string': ''},\n",
    "#         # this is a replacement for an edge\n",
    "#         goto=END,\n",
    "#     )\n",
    "\n",
    "# def _route(state):\n",
    "#     _step = _get_current_task(state)\n",
    "#     if _step is None:\n",
    "#         return \"solve\"\n",
    "#     else:\n",
    "#         return \"agent_exec\"\n",
    "# graph = StateGraph(ResearchTeamState)\n",
    "\n",
    "# # graph.add_node('decompose_or_rephrase', decompose_or_rephrase)\n",
    "# graph.add_node('get_plan', get_plan)\n",
    "# graph.add_node(\"agent_exec\", agent_exec)\n",
    "# graph.add_node(\"solve\", solve)\n",
    "\n",
    "# # graph.add_edge(START, 'decompose_or_rephrase')\n",
    "# graph.add_edge(START, 'get_plan')\n",
    "# # graph.add_edge('decompose_or_rephrase', 'get_plan')\n",
    "# graph.add_edge('get_plan', 'agent_exec')\n",
    "# graph.add_conditional_edges(\"agent_exec\", _route)\n",
    "# # graph.add_edge(\"solve\", END)\n",
    "\n",
    "# research_graph_compiled = graph.compile(checkpointer=memory)\n",
    "# research_graph = research_graph_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "# for s in research_graph.stream({'messages': [HumanMessage('what about sparse pca, why dont we use it instead of standardd pca? how is it an continous opt problem?')]}, config=config):\n",
    "#   print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research_graph.get_state(config=config, subgraphs=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from typing import TypedDict, List, Literal, Dict\n",
    "\n",
    "# # # Define Worker roles\n",
    "# # Workers = Literal['research_team', 'documentation_team', 'LLM']\n",
    "\n",
    "# # # Prompt for supervisor managing teams with task assignments and dynamic sequence creation\n",
    "# # members = \", \".join(['research_team', 'documentation_team', 'LLM'])\n",
    "\n",
    "# prompt = f'You are a supervisor and your task is to delegate to one of the members from: {members}.' + '''\n",
    "\n",
    "#     ### Guidelines:\n",
    "#     1. **Casual or General Queries**: \n",
    "#     - If the query is casual, general, or involves providing information that does not require specific investigation, delegate the task to the 'LLM' to answer directly.\n",
    "#     - Example: If the question is \"What is the capital of France?\", delegate it to 'LLM' to provide the answer.\n",
    "\n",
    "#     2. **Task-Specific Queries**:\n",
    "#     - **Research Tasks**: If the query involves research, new findings, or needs further investigation (e.g., \"Can you research the latest advancements in AI?\" or \"Tell me more about quantum computing?\"), delegate the task to the **research_team**. **Do not** answer these types of questions directly with the 'LLM'.\n",
    "#     - Example: For a question like \"Can you research the latest advancements in AI?\", delegate it to 'research_team' to gather research findings.\n",
    "\n",
    "#     3. **Output Format**:\n",
    "#     - Your output should be formatted as a dictionary with workers as keys and their respective tasks as values.\n",
    "#     - Each key represents the worker (either 'LLM' or 'research_team') who will be responsible for completing the task.\n",
    "#     - Each value represents the task assigned to that worker.\n",
    "\n",
    "#     Example output format:\n",
    "\n",
    "\n",
    "#     {{\n",
    "#         'LLM': 'Answer the question: \"What is the capital of France?\"',\n",
    "#         'research_team': 'Research the latest advancements in AI.'\n",
    "#     }}\n",
    "\n",
    "\n",
    "#     ### Warnings:\n",
    "#     - Make sure that tasks are assigned logically:\n",
    "#     - LLM should handle simple informational queries.\n",
    "#     - Research_team should handle queries requiring detailed research or new findings.\n",
    "#     - Ensure the tasks are clearly assigned and that the workers can perform them based on their capabilities.\n",
    "#     - If the query is neither casual nor requiring research, it may not need to be delegated. Handle such edge cases appropriately.\n",
    "\n",
    "#     ---\n",
    "\n",
    "#     ### Examples:\n",
    "\n",
    "#     1. **Casual Query Example**:\n",
    "#     **Question**: \"What is the tallest mountain in the world?\"\n",
    "#     **Output**:\n",
    "\n",
    "#     {{\n",
    "#         'LLM': 'Answer the question: \"What is the tallest mountain in the world?\"'\n",
    "#     }}\n",
    "\n",
    "\n",
    "#     2. **Research Query Example**:\n",
    "#     **Question**: \"Can you research the latest advancements in quantum computing?\"\n",
    "#     **Output**:\n",
    "\n",
    "#     {{\n",
    "#         'research_team': 'Research the latest advancements in quantum computing.'\n",
    "#     }}\n",
    "\n",
    "\n",
    "#     3. **Mixed Query Example**:\n",
    "#     **Question**: \"Tell me about the capital of Japan, and also research the impacts of artificial intelligence on education.\"\n",
    "#     **Output**:\n",
    "\n",
    "#     {{\n",
    "#         'LLM': 'Answer the question: \"What is the capital of Japan?\"',\n",
    "#         'research_team': 'Research the impacts of artificial intelligence on education.'\n",
    "#     }}\n",
    "\n",
    "\n",
    "#     Question: {question}\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "# # Define the SequenceCreator class to represent the sequence of workers and their tasks\n",
    "# class SequenceCreator(TypedDict):\n",
    "#     \"\"\"Defines the sequence of workers and their tasks.\"\"\"\n",
    "#     passes: Dict[Workers, str]\n",
    "\n",
    "#     def __init__(self, workers_tasks: Dict[Workers, str]):\n",
    "#         # Simply assign the workers' tasks without adding 'FINISH'\n",
    "#         self.passes = workers_tasks\n",
    "\n",
    "# # Template for the chat\n",
    "# template = ChatPromptTemplate.from_messages([\n",
    "#     ('system', prompt),\n",
    "#     MessagesPlaceholder(variable_name=\"messages\"),\n",
    "# ])\n",
    "\n",
    "# # Structured LLM output to map workers to tasks\n",
    "# structured_llm_output = llm.with_structured_output(SequenceCreator)\n",
    "\n",
    "# # Response chain to generate the task sequence and description\n",
    "# response_chain = template | trimmer | structured_llm_output \n",
    "\n",
    "# # Invoke response chain with the user query\n",
    "# response = response_chain.invoke({\n",
    "#     'messages': [\n",
    "\n",
    "#     ],\n",
    "#     'question': 'search researches on nova'\n",
    "# })\n",
    "\n",
    "# # Extracting the worker sequence and their tasks from the response\n",
    "# worker_tasks = response['passes']  # Dictionary with worker as key and task as value\n",
    "\n",
    "# # Output the task dictionary\n",
    "# worker_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workers = Literal['research_team', 'documentation_team', 'LLM']\n",
    "\n",
    "# members = \", \".join(['research_team', 'documentation_team', 'LLM'])\n",
    "\n",
    "\n",
    "# supervisor_prompt = f'You are a supervisor managing the given teams: {members}' + '''\n",
    "# Your task is to handle user queries by maintaining a seamless and cohesive conversation flow, ensuring that the user feels like they are interacting with a single agent, even when tasks are being delegated. \n",
    "\n",
    "# Each worker will perform a task and respond with their results and status.\n",
    "\n",
    "# ### Guidelines:\n",
    "# 1. **Casual or General Queries**: \n",
    "#    - If the query is casual, general, or involves providing information that does not require specific investigation or documentation answer directly as the 'LLM'. \n",
    "#      - **LLM Response**: Directly respond with the most relevant answer, utilizing your knowledge base.\n",
    "   \n",
    "# 2. **Task-Specific Queries**:\n",
    "#    - **Research**: If the query involves research, new findings, or needs further investigation (e.g., \"Can you research anti-matter further?\"), the task should be delegated to the research team. **Do not** answer these types of questions with the LLM.\n",
    "   \n",
    "#    - **Documentation**: If the query involves creation of new .txt files or manipulation of existing .txt files, the `documentation_team` should be involved.\n",
    "\n",
    "# 3. **Seamless Interaction**: \n",
    "#    - When delegating a task, the response should be phrased in a way that makes it feel like a single agent is handling the request, without referring to multiple teams. For example:\n",
    "#      - For research tasks: \"I'll gather more details on this topic for you.\"\n",
    "#      - For documentation tasks: \"Let me prepare the document based on the latest research.\"\n",
    "\n",
    "# 4. **Context Handling**: \n",
    "#    - You have access to the latest conversation history (limited by the context window) and should handle queries based on this context. \n",
    "#    - Teams (research and documentation) do not have access to the conversation history, so it is the supervisorâ€™s responsibility to track and respond accordingly, incorporating past messages to provide a cohesive conversation flow.\n",
    "\n",
    "# 5. **Maintain Context**: \n",
    "#    - If the user is following up on a previous discussion (e.g., \"Did you find the research on anti-matter?\"), ensure the response feels like part of an ongoing conversation, keeping the user informed without mentioning team involvement. For example:\n",
    "#      - \"I'm still gathering the latest research and will prepare the summary soon.\"\n",
    "\n",
    "# 6. **Proactive Engagement**: \n",
    "#    - Feel free to initiate conversations or ask the user if they'd like more details on a topic based on prior discussions. This will help create a more cohesive experience.\n",
    "\n",
    "# ### Task Assignment:\n",
    "# Please generate the task sequence and provide suitable tasks for each worker. Format the output as a dictionary with workers as keys and their tasks as values.\n",
    "\n",
    "# ### WARNINGS:\n",
    "# 1. The `documentation_team` should only be involved if the user **explicitly** requests document creation, file manipulation, or text editing. \n",
    "#    **Do not** involve the `documentation_team` for general research or information gathering unless the user directly and clearly asks for it, such as requesting a report, summary, or document preparation. \n",
    "# 2. Ensure that the tasks are assigned in a logical, clear, and accurate order of execution.\n",
    "\n",
    "# Question: {question}\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal, Dict, TypedDict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreState(TypedDict):\n",
    "  messages: Annotated[List[BaseMessage], operator.add]\n",
    "  passes: Dict[str, str]\n",
    "  call_next: str\n",
    "  current_task: str\n",
    "\n",
    "class ResearchTeamState(TypedDict):\n",
    "  messages: Annotated[List[BaseMessage], operator.add]    \n",
    "  task: str\n",
    "  plan_string: str\n",
    "  steps: List\n",
    "  results: dict\n",
    "  result: str\n",
    "\n",
    "  current_task: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Workers = Literal['research_team', 'LLM']\n",
    "\n",
    "members = \", \".join(['research_team', 'LLM'])\n",
    "\n",
    "supervisor_prompt = f'You are a supervisor and your task is to delegate to one of the members from: {members}.' + '''\n",
    "\n",
    "    ### Guidelines:\n",
    "    1. **Casual or General Queries**: \n",
    "    - If the query is casual, general, or involves providing information that does not require specific investigation, delegate the task to the 'LLM' to answer directly.\n",
    "    - Example: If the question is \"What is the capital of France?\", delegate it to 'LLM' to provide the answer.\n",
    "\n",
    "    2. **Task-Specific Queries**:\n",
    "    - **Research Tasks**: If the query involves research, new findings, or needs further investigation (e.g., \"Can you research the latest advancements in AI?\" or \"Tell me more about quantum computing?\"), delegate the task to the **research_team**. **Do not** answer these types of questions directly with the 'LLM'.\n",
    "    - Example: For a question like \"Can you research the latest advancements in AI?\", delegate it to 'research_team' to gather research findings.\n",
    "\n",
    "    3. **Output Format**:\n",
    "    - Your output should be formatted as a dictionary with workers as keys and their respective tasks as values.\n",
    "    - Each key represents the worker (either 'LLM' or 'research_team') who will be responsible for completing the task.\n",
    "    - Each value represents the task assigned to that worker.\n",
    "\n",
    "    Example output format:\n",
    "\n",
    "\n",
    "    {{\n",
    "        'LLM': 'Answer the question: \"What is the capital of France?\"',\n",
    "        'research_team': 'Research the latest advancements in AI.'\n",
    "    }}\n",
    "\n",
    "\n",
    "    ### Warnings:\n",
    "    - Make sure that tasks are assigned logically:\n",
    "    - LLM should handle simple informational queries.\n",
    "    - Research_team should handle queries requiring detailed research or new findings.\n",
    "    - Ensure the tasks are clearly assigned and that the workers can perform them based on their capabilities.\n",
    "    - If the query is neither casual nor requiring research, it may not need to be delegated. Handle such edge cases appropriately.\n",
    "    - If you're unsure about the user's request or lack context, always route to 'LLM' to ask for clarification instead of making assumptions or taking random actions.\n",
    "    ---\n",
    "\n",
    "    ### Examples:\n",
    "\n",
    "    1. **Casual Query Example**:\n",
    "    **Question**: \"What is the tallest mountain in the world?\"\n",
    "    **Output**:\n",
    "\n",
    "    {{\n",
    "        'LLM': 'Answer the question: \"What is the tallest mountain in the world?\"'\n",
    "    }}\n",
    "\n",
    "\n",
    "    2. **Research Query Example**:\n",
    "    **Question**: \"Can you research the latest advancements in quantum computing?\"\n",
    "    **Output**:\n",
    "\n",
    "    {{\n",
    "        'research_team': 'Research the latest advancements in quantum computing.'\n",
    "    }}\n",
    "\n",
    "\n",
    "    3. **Mixed Query Example**:\n",
    "    **Question**: \"Tell me about the capital of Japan, and also research the impacts of artificial intelligence on education.\"\n",
    "    **Output**:\n",
    "\n",
    "    {{\n",
    "        'LLM': 'Answer the question: \"What is the capital of Japan?\"',\n",
    "        'research_team': 'Research the impacts of artificial intelligence on education.'\n",
    "    }}\n",
    "\n",
    "\n",
    "    Question: {question}\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: List[str], prompt_for_supervisor: str):\n",
    "  options = members\n",
    "  system_prompt = prompt_for_supervisor\n",
    "\n",
    "  class SequenceCreator(TypedDict):\n",
    "      \"\"\"Defines the sequence of workers and their tasks.\"\"\"\n",
    "      passes: Dict[Workers, str]\n",
    "      def __init__(self, workers_tasks: Dict[Workers, str]):\n",
    "          self.passes = workers_tasks\n",
    "\n",
    "  def supervisor_node(state):\n",
    "      template = ChatPromptTemplate([\n",
    "      ('system', system_prompt),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "      ])\n",
    "      print('\\nQUESTION: ',state['messages'][-1].content, '\\n')\n",
    "      structured_llm_output = llm.with_structured_output(SequenceCreator)\n",
    "\n",
    "      response_chain = template | trimmer | structured_llm_output\n",
    "      # return response_chain\n",
    "\n",
    "      response = response_chain.invoke({'question': state['messages'][-1].content, 'messages': state['messages']})\n",
    "      return {'passes': response['passes']}\n",
    "\n",
    "      # return Command(goto='router', update={'passes': response['passes']})\n",
    "\n",
    "   #  response = response_chain.invoke({})\n",
    "\n",
    "   #  work_sequence = response['passes']\n",
    "\n",
    "   #  next_worker = work_sequence[0]\n",
    "\n",
    "   #  if goto == \"FINISH\":\n",
    "   #      next_worker = END\n",
    "\n",
    "   #  return Command(update={'passes': work_sequence, 'call_next': next_worker}, goto=next_worker)\n",
    "  \n",
    "  return supervisor_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervisor_node = make_supervisor_node(llm=llm, members=['research_team', 'documentation_team', 'LLM'], prompt_for_supervisor=supervisor_prompt)\n",
    "core_supervisor_node = make_supervisor_node(llm=llm, members=['research_team', 'LLM'], prompt_for_supervisor=supervisor_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: CoreState) -> Command[Literal[\"LLM\", 'research_team', END]]:\n",
    "    if not state['passes']:\n",
    "        return Command(goto=\"__end__\", update={'call_next': '', 'passes': {}, 'current_task': ''})\n",
    "\n",
    "    # print('\\nWORKING LIST: ', state['passes'], '\\n')\n",
    "\n",
    "    worker, task_value = next(iter(state['passes'].items()))\n",
    "    print(f'\\nNEXT WORKER: {worker}, TASK: {task_value}')\n",
    "\n",
    "    del state['passes'][worker]\n",
    "\n",
    "    return Command(goto=worker, update={'call_next': worker, 'current_task': task_value, 'passes': state['passes']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# research team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plan(state:ResearchTeamState) -> Command[Literal[\"agent_exec\", END]]:\n",
    "    try:\n",
    "        regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "\n",
    "        task = state['current_task']\n",
    "        messages = state['messages']\n",
    "        print('\\nCURRENT PLAN QUERY:', task)\n",
    "\n",
    "        metadata_info = get_metadata_info(conn_string=conn_string, user_id=user_id, con_id=con_id)\n",
    "\n",
    "        rag_guidance = check_knowledge_base.invoke({'query': task, 'data': metadata_info, 'recent_messages': messages[-12:]})\n",
    "        plan = planner_chain.invoke({'task': task, 'knowledge_chain_answer': rag_guidance, 'messages': messages})\n",
    "\n",
    "        # print('\\nMETADATA INFO: ',metadata_info, '\\n')\n",
    "        print('\\nRAG GUIDANCE: ',rag_guidance, '\\n')\n",
    "\n",
    "        # print(plan, '\\n', f'{\"-\" * 56}', '\\n')\n",
    "\n",
    "        matches = re.findall(regex_pattern, plan)\n",
    "        print(f'\\n PLAN: {plan}\\n')\n",
    "        return Command(update={\"steps\": matches, \"plan_string\": plan, 'task': task}, goto='agent_exec')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return Command(update={\"steps\": [], \"plan_string\": \"\", 'task': ''}, goto=END)\n",
    "\n",
    "\n",
    "  \n",
    "rag_agent = create_react_agent(llm, tools=[qdrant_retriever_tool])\n",
    "search_agent = create_react_agent(llm, tools=[tavily_search_tool])\n",
    "arxiv_agent = create_react_agent(llm, tools=[arxiv_search_tool])\n",
    "code_agent = create_react_agent(llm, tools=[repl_tool])\n",
    "\n",
    "\n",
    "def code_node(state: ResearchTeamState):\n",
    "    return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Coder\")]}\n",
    "\n",
    "def retriever_node(state: ResearchTeamState):\n",
    "    return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Retriever\")]}\n",
    "\n",
    "def search_node(state: ResearchTeamState):\n",
    "    return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"Searcher\")]}\n",
    "\n",
    "def arxiv_search_node(state: ResearchTeamState):\n",
    "    return {\"messages\": [HumanMessage(content=state['messages'][-1].content, name=\"ArXivSearcher\")]}\n",
    "\n",
    "\n",
    "def _get_current_task(state: ResearchTeamState):\n",
    "    if \"results\" not in state or state[\"results\"] is None:\n",
    "        return 1\n",
    "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "        return None\n",
    "    else:\n",
    "        return len(state[\"results\"]) + 1\n",
    "\n",
    "\n",
    "\n",
    "def agent_exec(state: ResearchTeamState):\n",
    "    \"\"\"Worker node that executes the agents accordingly for a given plan.\"\"\"\n",
    "    try:\n",
    "\n",
    "        _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "        _step = _get_current_task(state)\n",
    "        step_desc, step_name, agent, agent_input = state[\"steps\"][_step - 1]\n",
    "\n",
    "        # Replace placeholders in agent_input with corresponding results\n",
    "        for k, v in _results.items():\n",
    "            agent_input = agent_input.replace(k, v) \n",
    "\n",
    "        # Dynamically select the agent function based on the agent name\n",
    "        if agent == \"RagSearcher\":\n",
    "            result = rag_agent.invoke(retriever_node(state))['messages'][-1].content\n",
    "        elif agent == \"Searcher\":\n",
    "            result = search_agent.invoke(search_node(state))['messages'][-1].content\n",
    "        elif agent == \"ChatBot\":\n",
    "            result = llm.invoke(agent_input)  # Assuming LLM invocation does not need message formatting\n",
    "        elif agent == \"Coder\":\n",
    "            result = code_agent.invoke(code_node(state))['messages'][-1].content\n",
    "        elif agent == \"ArXivSearcher\":\n",
    "            result = arxiv_agent.invoke(arxiv_search_node(state))['messages'][-1].content\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown agent type: {agent}\")\n",
    "\n",
    "        if result is None:\n",
    "            raise ValueError(f\"Agent {agent} did not return a result for step {step_name}\")\n",
    "\n",
    "        # Store the result in the _results dictionary\n",
    "        _results[step_name] = str(result)\n",
    "\n",
    "        return {\"results\": _results}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {'plan_string': \"\", 'steps': [], 'results': {}, 'result': \"\"}\n",
    "\n",
    "solve_prompt = \"\"\"\n",
    "We have created a detailed step-by-step Plan to solve the given task and obtained corresponding answers from agents for each step in the Plan. \n",
    "Use these agent-provided answers as Evidence to craft a clear, comprehensive, and cohesive response.\n",
    "\n",
    "Here are some recent few messages to give you a context of the conversation:\n",
    "{recent_messages}\n",
    "\n",
    "Plan:  \n",
    "{plan}\n",
    "\n",
    "Using the Evidence from the answers provided for each step in the Plan, solve the given task:  \n",
    "Task: {task}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def solve(state: ResearchTeamState) -> Command[Literal[END]]:\n",
    "    try:\n",
    "        plan = \"\"\n",
    "        for _plan, step_name, agent, agent_input in state[\"steps\"]:\n",
    "            _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "            for k, v in _results.items():\n",
    "                agent_input = agent_input.replace(k, v)\n",
    "                step_name = step_name.replace(k, v)\n",
    "            plan += f\"Plan: {_plan}\\n{step_name} = {agent}[{agent_input}]\"\n",
    "\n",
    "        print('\\nplan:', plan)\n",
    "        \n",
    "        prompt = solve_prompt.format(plan=plan, task=state['current_task'], recent_messages=state['messages'][-12:])\n",
    "        result = llm.invoke(prompt)\n",
    "        \n",
    "        return Command(\n",
    "            update={\n",
    "                \"result\": result.content,\n",
    "                'messages': [result],\n",
    "                'results': {}, \n",
    "                'steps': [],\n",
    "                'task': '',\n",
    "                'plan_string': '',\n",
    "                'current_task': ''\n",
    "            },\n",
    "            goto=END,\n",
    "        )\n",
    "        # return {\n",
    "        #         \"result\": '',\n",
    "        #         'messages': [result],\n",
    "        #         'results': {}, \n",
    "        #         'steps': [],\n",
    "        #         'task': '',\n",
    "        #         'plan_string': '',\n",
    "        #         'current_task': '',\n",
    "        #     },\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return Command(update={'task': '', 'plan_string': '', 'steps': [], 'results': {}, 'result': \"\", 'current_task': ''}, goto=END)\n",
    "        # return e\n",
    "\n",
    "\n",
    "def _route(state: ResearchTeamState):\n",
    "    _step = _get_current_task(state)\n",
    "    if _step is None:\n",
    "        return \"solve\"\n",
    "    else:\n",
    "        return \"agent_exec\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_graph = StateGraph(ResearchTeamState)\n",
    "\n",
    "# graph.add_node('decompose_or_rephrase', decompose_or_rephrase)\n",
    "research_graph.add_node('get_plan', get_plan)\n",
    "research_graph.add_node(\"agent_exec\", agent_exec)\n",
    "research_graph.add_node(\"solve\", solve)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # research_graph.add_edge(START, 'decompose_or_rephrase')\n",
    "research_graph.add_edge(START, 'get_plan')\n",
    "# # research_graph.add_edge('decompose_or_rephrase', 'get_plan')\n",
    "# research_graph.add_edge('get_plan', 'agent_exec')\n",
    "research_graph.add_conditional_edges(\"agent_exec\", _route)\n",
    "\n",
    "research_graph = research_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state: CoreState):\n",
    "  task = state['current_task']\n",
    "\n",
    "  llm_prompt = \"\"\"\n",
    "You are a helpful assistant with access to the current conversation history, but only up to the context window size. Your task is to assist to the best of your abilities, based on the information provided. Please consider the context in which the task is given and strive to perform it as effectively and satisfactorily as possible. \n",
    "\n",
    "Remember:\n",
    "- Use the conversation history to understand the context of the task.\n",
    "- Answer concisely but thoroughly based on the information available.\n",
    "\n",
    "Task: {task}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "  template = ChatPromptTemplate(\n",
    "    [\n",
    "      ('system', llm_prompt),\n",
    "      MessagesPlaceholder('messages')\n",
    "    ]\n",
    "  )\n",
    "  llm_chain = template | trimmer | llm\n",
    "  llm_response = llm_chain.invoke({'task': task, 'messages':state['messages']})\n",
    "  return {'messages': [llm_response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAFcCAIAAABZe251AAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/DPJWEmYSXs7SoKKCpYt1Zw4UQUreK2atWqVdtaq1+tg1pt3VatExVFURFxoWipigutqGhFEJChjARIyF73++P6o1YBGUnuEt7PP/qA43L3TigvP/e5z30+GI7jCAAAqIdGdgEAAFAziCcAAEVBPAEAKAriCQBAURBPAACKgngCAFAUg+wCqKKiVFFVoZJUqWQijUKuIbucejExw+h0zNKKYcmmO7ibMUzgHxtgVLBmPu7pba4056k495nYzslUKdNYshksGzqdYRh/5yYWNCFPKRGqJFXq0gK5Swtzbz9mm85sc0s62aUBoAXNN554RfLURB7LmmHraOrty7R1NCW7oqbKz5TkZohLXsvcP7HsNoRDdjkANFUzjadbCbyCl5Iew7gePpZk16J9D66W37tcHjLB8ZNObLJrAaDxml08qVX48Q353YZxWvqzyK5FhzRq/OZZHsME6zGcS3YtADRS84ontQrfs/TV59962DoY/KVcffx1vUJSpe45AhIKGKRmFE8KuebAipzZG1qRXYhePUguLyuQD57qTHYhADRYM4qn6DV5YXNcrTgmZBeib/cu8TEa1mWgHdmFANAwhnEHven+PFXad4x9M8wmhNCngzlyiTr3mZjsQgBomGYRT0XZUn6xwtOHSXYhpOnQx+bG6TKyqwCgYZpFPN1O5HUf1qy7h63sTDzaWmakCsguBIAGMP54yn0mcvIyd/I0J7sQkvUczn31VER2FQA0gPHHU3a62N7NTG+ny8jIkMvljXutWq1OT0/XdkX/MDGjadSoMEuio+MDoHXGH0+5GWJvPz31OiUmJk6ZMkUqlTbu5WvWrImKitJ2Uf/y9mPmZkAHOTAYRh5Pb15JPdtamlno6RHZRrebiOEdjX55PbX0Z/KLFTo9BQBaZOQTqlTylAwTTBdHfv369U8//ZSRkWFlZdWzZ8+lS5deuHBh/fr1CKGQkBCE0MqVK4cNG5aenr5v3z7iks3X13fhwoVt27ZFCFVWVoaEhCxYsCAzMzMlJcXHx8fNze3q1asIocDAQITQuXPnXFxctFsz286kMEuKa3CMppPPBADtMvJ4kghVllY6eY9r1qzJy8tbvHixWCx+8OABjUbr0aNHZGTk0aNHt2zZwmKxPDw8EEJv3ryRy+UzZsyg0WhxcXHz589PTEw0N/+nn37//v1jxozZvXs3nU5nMpklJSVFRUWrV69GCHG5OrnVyLSii4Vqlo2R/96BcTDy/01FAhXHSSf94m/evPHx8QkLC0MIRUZGIoTs7Ozc3NwQQn5+fjY2NsRugwcPDg0NJb5u167d7Nmz09PTu3btSmzx9/efO3du9TFtbGz4fH5AQIAuCiYwrRhioQriCRgEI//fFMMwHV3chYaGHjp0aMOGDTNmzLCzq/V5EQzD/vjjj6NHj+bm5lpaWiKE+Hx+9U+7dOmii9rqYGZJww1jKlAAjL1r3NySVlWp0sWR586du2jRoitXrgwfPvzkyZO17bZv375vvvmmXbt2mzZtWrhwIUJIo/k3HiwsLHRRWx0qS5WWVjCXJjAMRh5PTGuGWKCTeMIwbPz48QkJCX369NmwYcO745Wqn7KWy+UHDx4cOXLk4sWLAwIC/P39P3pYXT+hLRaqmLrpjANA64w8nqw4Jphu3iIxCIDJZM6ePRsh9OLFi+rWUFnZP0+3SaVSuVxO3Koj7ta913p6j4WFBZ/Pr2OHJpKJ1W5tLOgMuG0HDIOR/0Pq8Yll4p43vUfZ07R9K/27775jsVhdu3a9desWQojIoA4dOtDp9F9++WX48OFyuTw8PLxVq1axsbEcDkckEv3+++80Gi07O7u2Y3bq1OncuXNRUVEBAQFWVla9e/fWbs05T8XQdAIGhL5q1Sqya9CtskK5iSmm9ZUOCgsLb926dfnyZalU+tVXX/Xt2xchZGVl5ejoePXq1Zs3bwqFwqFDh3bq1Ck1NfXkyZOvX7/+6quvPD09T58+PWHCBKVSefjw4Z49e7Zr1676mK1atRIIBJcvX/7rr79sbGy03nF+P6m8dUeWESz6AJoJ45+OLvOhsLxYCSuXIIROby8Mm+uq9YYkADpi/E39TzpbRa/O8+1mZWVX81x0paWlERERH27HcRzHcRqthr6rBQsWECOedGrGjBk1Xgk6OjqWlJR8uH3EiBFff/11bUe7n1Tu1soCsgkYEONvPSGEsh5VvXoiHjTZqcafqlSq0tLSD7drNBqNRsNg1JDg1tbWTKbOHzMuKytTKpUfblcqlSYmNUStpaVl9XDQ96iUmr3Lcr/c2FIHZQKgK80inhBCSYeLA0NsOS76m1mFUtKulluy6L7drMkuBIAGMPKBBdUGRDoe/6WA7CrI8eKBsLJECdkEDE5ziSeMho1d7H7s53yyC9G3wizJoz8q+0c6kl0IAA3WXC7uCFUVysTf347/zoPsQvQk77k4PaVy5BxXsgsBoDGaVzwhhEoLZXGbC8d9466jmQyo4/GNyvwXkmEztTxpFAB60+ziCSGkUeNXYoppGNZ9GNcopxbJeSq6nchv04nVZRCM9gIGrDnGEyHzYdXtRF67T60cPc292hnDEnhioSo3Q1zwUqJRo+7DOLYOMDocGLbmG0+EF/eFWemi/BcS/17WNAxjWtNZ1gy6qWHcMaDTMZFAKRaoxUJVaYFcXKny9mP6dGE7e+l7nhYAdKG5xxNBo8FfPxdX8pRigVomVsulWp4zQCKR5OXlvft4nVawbBhqJc60pjOtGA7uZg4ezX0tP2BkIJ704eXLlytXrjx+/DjZhQBgSAzjKgYA0AxBPAEAKAriSR9oNJqnpyfZVQBgYCCe9EGj0bx+/ZrsKgAwMBBPesJiscguAQADA/GkJyKRiOwSADAwEE/6gGGYjhYlB8CIQTzpA47jPB6P7CoAMDAQT/qAYViLFi3IrgIAAwPxpA84jufk5JBdBQAGBuIJAEBREE/6gGGYtTVM9Q1Aw0A86QOO4wKBgOwqADAwEE/6gGFYbSvQAQBqA/GkDziOV1ZWkl0FAAYG4gkAQFEQT/qAYZirK6zmBEDDQDzpA47jRUVFZFcBgIGBeAIAUBTEkz5gGObt7U12FQAYGIgnfcBxPDc3l+wqADAwEE8AAIqCeNIHmLEAgEaAeNIHmLEAgEaAeAIAUBTEkz7AQlIANALEkz7AQlIANALEEwCAoiCe9ATWuQOgoSCe9ATWuQOgoSCe9AHDMHd3d7KrAMDAQDzpA47jBQUFZFcBgIGBeAIAUBTEkz5gGMbhcMiuAgADA/GkDziO8/l8sqsAwMBAPOkDPBIMQCNAPOkDPBIMQCNAPOkDjUaD2TIBaCiIJ33QaDQwWyYADQXxpA8Yhjk6OpJdBQAGBsNxnOwajNa4ceMkEgmO4yqVSiAQcLlcHMcVCkVSUhLZpQFgAKD1pEPDhg0rLi5++/ZtWVmZQqF48+bN27dv2Ww22XUBYBggnnQoIiLivUftMAzr06cPeRUBYEggnnTIxMQkPDycTqdXb/Hw8Bg9ejSpRQFgMCCedCsiIsLFxYX4GsOwvn37Ojs7k10UAIYB4km3GAxGREQE0YDy8PAIDw8nuyIADAbEk86NHj3axcWF6HWqbkkBAD6KQXYBdVHINeXFCkmVCiGM7FqaZET/mSkpKT07hedkiMmupUloGLJxMLGxNyW7ENAsUHfc082zvOz0Kks2w5xNx3DDjiejwbJhFGZJWLaMjn1svP2YZJcDjBxF4+ny4WJrrplfD1uyCwE1UKs0yUffBPa39WoHCQV0iIrxlHy8xIpj1vZTG7ILAXW5uL+g10iuSwsLsgsBRotyXeNlhTJJlQayifq6DXP463ol2VUAY0a5eCovUTJMoKfJANjYm+Y9N+yefkBxlIsnsUBlY29GdhXg4zAMc/I0F/CUZBcCjBbl4kmjRiqlhuwqQL2IBCqMBk1doCuUiycAACBAPAEAKAriCQBAURBPAACKgngCAFAUxBMAgKIgngAAFAXxBACgKIgnAABFQTwBACgK4gkAQFEQT0bi4qWEkaNCSkqKyS4EAK2BeDISpqZmTCaLRoNfKDAelF4KQT9wHMcwA3jsvu46Q4IHhQQP0vVZANAnI4mni5cSzsTH5ufnsVjs7t16T582x9bWTqVSHTy0O+nKeYGg0tPTe8rkWT179EUIpfyZ/OPqpWt+/OVE3JEXL559Pm7ytKlfymSyfft3Xrt+WaGQu7t5RkRM7PfZgDrOKJPJtmxbf/v2DYRQ+/Yd581Z4uTk/NWC6RbmFht+3kHsc+Lkkd17tl6+mGpmZjZsRF+fT3ylMml2dqa1tc3AAUMnTfyCwfjn8084d+pk3FEer9TJySW436CxERPNzMwEgsqRo0Jmz1qQlZ2ZmprSurWPpSUzJycr9th5opUklUrDxwwYNjRcIKxMSjqPELqadJfBYNy9e+v3fdvfvCl0cnIZPmz0qLCxCCE+n7dr9+Z791NVKpW/X8DsWQtbtGhV26ehl18aAB9hDPF0KHpP9OG9ffuEjAmfUFFZnpZ2h2FighD65de1ydcuRU6Y5uXVMvnapRX/W7J189727TsSr9q6/ecZ0+ZOm/qlm6uHRqP5YfnXxcVvJoyfamNjl57+YM3aZTKZNHTwiNpOeuz4waSk81OnzOZwuElXzltYfHzK7fyCvC9nf83l2N+5ezPm2EGRqGr+V98ihA5F/x536uiosHGeni0KCvJOnDxcWJS/bOlq4lVHj+4fMWLMr7/sptPpZaUlK1YuSX/8sFPHIITQrVt/SKXSYcPCJRKxRqO5evUiQkgikaxa/Z2XZ4vFi5bn5mbz+WVEmC5aMlsoFMz8Yr65mfnxE9GLlsw+cjiezWJ/+Glo6dcCQFMZfDyVlZUejTnQv39o9d/zuLGTEEL5+XlJV85PmjhjyuRZCKE+vYMjJ4Udit6z6dfdxG5hI8cOHDiU+Drlz+QnTx8dj0nkcu2JCyWpVHL6zPE64ult8RsLC4vxn09hMBhDQkfWp9S+ffr37ROCEPLz6yAUChLPn5k8eZZSoYg5dmD5D+v69A4mduNw7Ddv+Wne3CXEt+3a+c+YPpf4ulXLNhwO9+rVi0Q8XU2+GNj5UzdXd4SQl2cLYp+KynK5XN6rV7/+IYOrT301+WJ+ft6vv+wiXujv33F85PAzZ2InT/riw08DAIow+Hj666/7arV6xLDR721//OQvhFDPnp8R32IYFhTY9WryxeodOnXqUv313bu3VCrV+Mjh1VvUajWTyarjvCHBg69du/zd0q/mzllMXCU1SJcu3c9fiM/KesHnlalUqnVRy9dFLSd+RKydwysr5XC479VJp9NDB484Ex+7cMFSkajq4V/3V/5v/XtHdnF29fVtfzRmv7m5xbCho0xNTRFCjx8/ZDFZRDYhhJycnD08vDJfPq/x0wCAIgw+nioqyxFC9vaO720Xi0UIIVsbu+otVlbWEolELP5n9n5LC8t/D1LB53C4m37Z/e4R6Iy6PpxPu3T/KWrr7j1bpn8xbkjoyIULljLq3P89LBYbISSVSvjlPIRQ1LotDv99Cy4ubsRbMDf/z2Vj6OCRR2MO3L5zo7S02NbWrnu33u8dGcOw9VHb9u3fsXvPlrhTR7//bnWHDp1EYpG1zX8WDbSysubzyqq/fffTAIAiDD6eiL/z8gq+g8N//ry5XAeEkFAoIK7XEELl5XwGg2Fubv7hQdhsq8rKCkdHZzOzBqzC8GmX7kGBXU+fOf7brs2Ojs4TI6fX/54Xr6yUSNXKygpii4eHV31e6OTkHBTU7WryxZKSt0NCR9aYiSwWa+GCpRERE1f8b/HyFYtOxF605zo8f/703X3Ky/mODk71rBYAUhj8MJmADp0RQhcvnq3eolKpEEJt2/phGHb33i1io0KhuHvvlq9vezqd/uFBOnXqolarzyWeqt4ilUrrPq9CoUAI0Wi0MaMncLn2WVkvEEI21rZEa4hQXPymxtfiOH7p8jk2i+3p4d2xYxCGYfFnT9T/1MOGjrp791ZeXs6Q0LAad5DL5cRV3qiwcSKxqLj4ja9v+6oq4d9/ZxA7vHqVVVRU4O8fUPeJACCXwbee3Nw8hg4JSzx/RigUBAV1EwgqExNPb9q0x9XFbeCAoYei96jVahcXtwsX4svL+cu+X1PjQfqHhCaeP7N7z9a3xW/atPbJzn55K/WPQwdO1djUIpyJj029/Wf/kFA+v4zHK/vkk3YIoaCgbjc3/3Ey7mhAQODt239eeCc0EUJ/pFzhcLhmZuZ//pn8KP3BrJnzLSws3FzdR4WNO33m+LLlX/fs0ZfP551NOPlT1NY2rX1qO3XXT3va2XF8fHzfazASlErl5Knhffv09/ZqmZAQx2KyXFzcPDy8Yo4dXLX6u4mRM2g02pEj+2xsbEcMH9PADxsAvTL4eEIIfb3weycnl/Pnz6Te/tOe6xAU1I1BZyCEFi5YymSy4s+eqKoSenu1jFq7ubpv+D0mJiYbf965d9/269eTzp8/4+bmMXzY6Lr7klxc3JQKxa7dm5lM1qhR48ZGTEQIDR40vLAwP/bE4SNH9/XuFRwxJjLm2MHql3C5DklXzhcUvHawd5w9awHxEoTQ3DmLHBwc4+NPpKXd4XC4vXp+Zs91qOPUDAYjdPAIX98ONf5UKpN2DAhKvnZJLBZ5e7eKWreFCNmNP+/8bdemXbs3azSa9v4d585ZbGtrV+MRAKAIjLhPRB0PrlZIRJqO/ThkF6Jlw0b0DR088svZC8kuRJtOb80bNc/Nys4Y/pEDFAT/Y9Vl774d73ZIVbNiW8ccTSCjIgCaEYinukRETBw6dNSH22mYwd9SAID6IJ7qYm1lbW1lrZVDJSakaOU4ADQf0AoAAFAUxBMAgKIgngAAFAXxBACgKIgnAABFQTwBACgK4gkAQFEQTwAAioJ4AgBQFMQTAICiKBdPphY0himss2YYbB1MaTXM7geAdlAunmzsTYpzPzJdJKACqUjFK5KzrOGxTaArlIsn11YWSoVGo6HWLFTgQ8V50k8617WYDQBNRLl4otOxrqGcq0dqnqUbUATvjezRdX7PkfZkFwKMGeVmyyS8zZVePFAc0M/Oxt6UaWVCdjng/2GovFguqlBmpgnGf+dBZ0AvIdAhisYTQkgsVD28VlGcJ5dUqRBFa6wvXKNRqlTEipgGzdbJlIYhtzYWHfva1mN3AJqEuvFkTF6+fLly5crjx4+TXQgAhoRyfU8AAECAeAIAUBTEkz5gGNaiRQuyqwDAwEA86QOO4zk5OWRXAYCBgXjSBwzDXF1dya4CAAMD8aQPOI4XFRWRXQUABgbiSR9oNJqnpyfZVQBgYCCe9EGj0bx+/ZrsKgAwMBBP+gB9TwA0AsSTPkDfEwCNAPEEAKAoiCd9wDDM3d2d7CoAMDAQT/qA43hBQQHZVQBgYCCeAAAUBfGkJ0Yw2RMAegbxpCcKhYLsEgAwMBBPesJkMskuAQADA/GkJ2KxmOwSADAwEE8AAIqCeNIHDMMcHBzIrgIAAwPxpA84jpeWlpJdBQAGBuIJAEBREE/6AA+1ANAIEE/6AA+1ANAIEE8AAIqCeNIHWEgKgEaAeNIHWEgKgEaAeAIAUBTEkz7AXOMANALEkz7AXOMANALEkz5gGMZms8muAgADA/GkDziOV1VVkV0FAAYG4gkAQFEQT/oAi5gD0AgQT/oAi5gD0AgQT/qAYZi3tzfZVQBgYCCe9AHH8dzcXLKrAMDAQDzpA4Zh0PcEQENBPOkDjuPQ9wRAQ0E86QP0PQHQCBiO42TXYLS++OILuVyO47hEIikpKWnRogWO4zKZLC4ujuzSADAADLILMGZ+fn5Hjhyp/vb58+cIIViyBYB6gos7HYqMjHR2dn5vY1BQEEnlAGBgIJ50iMPh9O/f/90tjo6OkZGR5FUEgCGBeNKtyMjI6jVacBzv2LFj69atyS4KAMMA8aRbdnZ2AwYMIL52cnKCphMA9QfxpHNjxowhxmQGBAT4+PiQXQ4ABgPu3CGEkEKqkcs0Ojq4Gd0muM/QpKSkseFTqipUOjoLjuNWdiY6OjgApGju454epVQ8uSnAMEyjNuzPwcbetOiVpIUfM7C/nb2bGdnlAKAFzTqeUk6VaXDkE2TDtjWGdodGgwt4ihuni/uNdXTxNie7HACaqvnG07XYUjNLeoc+HLIL0b7EPfmfjbF39rYguxAAmqSZdo0XZkk0GmSU2YQQCh7v8uBqBdlVANBUzTSeyorkdIbRvndLNqM4TyYTq8kuBIAmMdo/0bpJRWquszH3H3u0ZZWXKsiuAoAmaabxJBNrlCpj7nQT8hUYjpFdBQBN0kzjCQBAfRBPAACKgngCAFAUxBMAgKIgngAAFAXxBACgKIgnAABFQTwBACgK4gkAQFEQTwAAioJ4AgBQFMSTvolEopdZL8iuAgADAPGkbzNmjrt0KYHsKgAwABBPjdGUKUYVikbOc9Js5zUFzRbEU31NnR6xes33h4/sGzkqJHRoL5FIpFKp9u7bMTpiUP+BXWfM/PxWagqx54OH9z4LDnz+/Gn1awcP6fn73u0IoXHjh1ZUlJ9NiPssOHDc+KHET2Uy2Y6dv4aF9x8yrPfsLyde/+MKsT3lz+TPggNv3Ur5asH0/gO7xp44TMb7BoA0sJBUA6Sl3ZHJZVFrN0ukEhaLtf7nVcnXLkVOmObl1TL52qUV/1uydfPe9u071nGEVSs3fPvdvIAOnceMnmBiaooQ0mg0Pyz/urj4zYTxU21s7NLTH6xZu0wmk4YOHkG8ZOv2n2dMmztt6pce7l56ep8AUAPEUwPQGYwVP0RZWFgghPLz85KunJ80ccaUybMQQn16B0dOCjsUvWfTr7vrOILPJ+0YDAaHw/X3DyC23Lh5/cnTR8djErlce4RQSPAgqVRy+szx6ngKGzl24MChenl/AFALxFMDtG3rR2QTQujxk78QQj17fkZ8i2FYUGDXq8kXG3rMu3dvqVSq8ZHDq7eo1Womk1X9badOXbRROwCGB+KpASzM/12aSSwWIYRsbeyqt1hZWUskErFY3KBjVlTwORzupl/+0+aiM/79vVhaWDatagAMFcRTI3G5DgghoVBAXJQhhMrL+QwGw9zcHMM+Msn3u/fg2GyrysoKR0dnMzNjXpoBgEaAO3eN1LatH4Zhd+/dIr5VKBR3793y9W1Pp9OJJhWPX0b8iM/nKZXK6hdamFvw+bzqbzt16qJWq88lnqreIpVK9fg+AKAuaD01kquL28ABQw9F71Gr1S4ubhcuxJeX85d9vwYh5OHh5ejodPToflsbO4lUsn//To1GU/1Cf/+O165fPnb8EJtt5duuff+Q0MTzZ3bv2fq2+E2b1j7Z2S9vpf5x6MApc3NYhRw0dxBPjbdwwVImkxV/9kRVldDbq2XU2s2dOgYhhBgMxqqVG7Zu+/mb7+a6urpPnTx73U/Lq181a+b88nLekaP7bKxt58xZ1KJFq40/79y7b/v160nnz59xc/MYPmw0gwG/FwAQ1jzHIl8/UWrtYN6mkxXZhejK5YOFPYdznVtAEwwYMOh7AgBQFMSTccJxvKFDHACgGogn46TR4N9///369esRQvn5+VlZWWRXBECDQRescaLTadu2bTOxEiGEhELh2rVrO3fu/M033zx+/LiqqiowMBDuDALqg3gyZlwuFyHk5+cXGxurUqkQQjQaLS4uLicnZ9KkSUlJSSKRKCQkxNramuxKAagBxFNzQQxW8Pf337p1K7HFw8MjPj7exsYmODj4wIEDEolk3LhxRKIBQAUQT8ZPLBZXVFTw+fzy8nKhUDhixD9zIbRt27Zt27bE15999llKSkpxcTGXy125ciWO4wsXLrSzs6vzwADoFsST0dqxY0d+2WORSKTRaNRqtVKpVCqVIpGoOp7e5e3t7e3tTXw9d+7ctLQ04tmaCRMmsFisX3/9lcViVVVVsdlsvb8P0HxBPBkntVpdUFDwPOc5juM02r/3Z999vKY2Dg4OQ4YMIb6Ojo5+/Pgx8ZDzhAkTGAzGqVOnNBpNdna2j4+PLt8BADCwwEjR6fTZs2d7eXm9m00IIU9PzwYdh8FgdO7cmclkIoTOnTu3efNmDMM0Gs2aNWvmzJmDEMrIyLhx44ZMJtP2OwAA4sl4eXt7L1261M3NrXoLjuMcDichIUGtVjfumJ6enhiGmZqaxsTEbNu2jciv+Pj448ePI4SuXbsWFxfH4/HqcSQAPg7iyZgFBQXNnz/f3v6fGamsra3nzp37+PHjbt26LV++/N69e005OHEr0MfHZ/PmzVOnTkUIubu7v3r16o8//kAI3bx587fffnv16pWW3gpojuirVq0iuwYS5D4TmzMZHGejnQEuO13o8Ykl25bh7e3NZDKfPXsmlUodHR0XLlzYp0+fL774Qi6Xnzx5ctu2bZWVlY6OjjY2Nk0/KYfD6dmzp6+vL0LI0tLy1atXlZWV7dq1i46Ojo+Pb926tZWV0T6DDXShmcZTStJjVw9HW0ejjafSQpmThxnLlkEMIKDRaE+fPr18+XL1Dq1btx4yZMjgwYNfv369ffv2ixcvqtXqFi1aaGsuFyaT2alTp3bt2iGEvLy81Gq1paWlvb39okWLzp07FxQUxGQyFQoFnU7XyumAUWqOE6qEh4eH9vjSy6VDl8H2ZNeiK8d+ejV1lbepeX0v3jMyMhITE8+fPz9gwIB+/fr16tVLR4XJZLL09HRvb29HR8fp06eLxeJff/3V1dWVx+PBiFDwnmYUT+fPn7ewsAgODlYoFOVv1I9vCrsPdyS7KJ2oqlA8us4fMs25Ea9NSUk5e/bskydPRo4cOXjw4NatW+ugwH9lZWVxOBw7O7v//e9/d+/ePXDggJub24sXL2DUAmhG8XTlypXU1NRly5ZVrzhw6yxPIcfavEs7AAAgAElEQVSDBhlhA+rMttdDZzg1pWdNIBBcunTp7NmzNBptyJAhw4cP18OATD6fb2pqymaz58+ff+/evTt37qjV6nv37gUEBLBYrHocABgbI4+n9PT0U6dOrV27tsYRz/eTystLFJ8E2nBczD66vAr1ScUqAU9x83RJ2BxXW0dTrRwzMzPzwoULmZmZTCZzxIgRffr00cphP0qlUtHpdLVavXjx4sLCwtOnTwsEgtu3b3fu3NnBwUE/NQDSGW08lZeX29nZLViwYN68eXVcobxIEz65KRALVEpFkz4HDY7Tag84HOEaDU6n6XAYh52zaWWp0tvPsstAO7atidaP/+effyYkJLx69apfv34jRozw8tL3iupisfinn37i8/m7du0qKyu7fv16165dGzrKFBgWI4wnlUq1YsWKbt26DR8+vB67I4QQwpFc9vGnPWrz6NGjqKgoBoNBjE78UHZ29vr16/ft29foU3wUjiNzS52PYhMKhWfPnk1ISLCxsRkzZsygQYN0fcYaicXinTt38ni8DRs2ZGdn37x5s1+/fhBVxseo4kkikWAYxufznz9/PmDAAP2c9OLFizt27CgtLXV0dIyLi7O0rGFR37KyskuXLk2aNEk/JelBenp6SkrKsWPHwsLCwsLCSOzJFggER44codFoc+bMSU1Nffz4cWhoqP4bd0AXjCee4uPjN23alJycrM/ldqOjo48ePVpRUYEQcnZ23rt3r5OTk97OTjq1Wh0fHx8fH+/u7v7pp5+GhYWRWw+PxyNaduHh4QkJCXl5eeHh4e8+1gMMizE81FJSUkI8BHvz5k19ZtMvv/xy6NAhIpuIv1WhUFjjnhUVFdeuXdNbYXpDp9NHjx4dExMzderUZ8+eBQYG/vTTT9nZ2WTVw+Vyp0+fHh4ejhDq2rWrra0tUcyBAwc2btz49u1bsgoDjWPYraeioqLZs2fv2LFD//0Oy5Yte+9JfTs7u6ioqMDAwA93zsrKWrFiRWxsrH5r1Dccx0+fPp2amioQCCIiIsjqmfpQcXFxSkpK69atO3fu/OuvvyqVyhkzZsAoUOoz1IdacnJybG1tnz59OnHiRHd3d/0XsGnTpsrKyneHI2AY1rNnzxp7PUxNTZ2dnavnezNWGIa1a9du0KBBXl5ely5dWrt2LY7j3t7epC+7wGKx/Pz8XFxcEEItW7asqqqytrbmcDgrVqxIS0sLCAgwNdXOOAygXQbZetq8eXNeXl71nNkkCgsLKygoIL6m0Wg//vjj4MGDyS6KKiorK8+dOxcdHd2tW7fx48cTz99Rytu3b2/evNm7d28nJ6d58+Z5enp+/fXXsII8dRhY6+nly5ccDkcqlRJzoZHO2dlZJpOdPn06Li5OLBYHBAS0b9/+w90kEkliYmL1xN7NhLm5eYcOHSZPniyXy3ft2pWcnGxhYUGpJiSbzfb19SWGpPv6+gqFwtatW5uYmEyaNInP53fq1InsAps93EAUFRX179//xYsXZBfyH6tXr753795Hd5NIJD169NBLRdSVnp6+ZMmS4cOHx8XFkV3LR2RkZMTGxuI4npub+8UXX5w9e5bsipopA4in0tJSHMfv3LnD4/HIruU/cnJywsPD67lzbGysWq3WcUUGoKCgICoqKiQkZO/evQbxgTx48CA+Pp6I1/nz56ekpJBdUTNC9b6n6OjotLS0HTt2kF1IDX7++WdfX9+hQ4eSXYjhkclkBw8ePHDgwMSJE6dPn07MZU5xOI6npqaWlJSEh4enpqZeuXIlPDy8xmt5oC3UjaeysjJ7e/tjx46NHz+e7FpqUF5ePnbs2KtXr9Zz/7NnzwYGBsIQwfdER0dfvHjx008/nT17do0D7qlJJpMlJycrlcqwsLALFy7k5OSMGTOmWY3I1Q+Kdo0vW7bM1dXVxcXF39+f7Fpqtn///uDg4Pr3dickJIhEImKiW1AtICBgzJgxOTk5CxcurKqq6tixo0HcOGMwGG3atCF++/b29rm5uVKptGXLlkePHs3MzGzdujXMAqoVVGw9Xb16VaPRDBw4kOxCalVSUjJ16tSLFy/W/yWZmZkCgaBLly66rMuwHT58+M6dO4GBgdOnTye7lkb6+++/ExISRo0a1aZNm8OHD7dp06Zr165kF2XIyO78+pdKpVq8eDHZVdTL1q1bk5OTya7COO3cubN3795Eb7RBu3Tp0pw5czIzM3Ecv3r1allZGdkVGR4KPXO3atWqGtfXpprHjx+np6cHBwc39IXr1q1TqVS6Kcp4zJkz58KFC8TzABkZGWSX03iDBg3auXNnmzZtiBl1JkyYUFlZiRB68eIF2aUZDrLzEcdx/ODBg2SX0ADjxo0j/klsqCVLlly7dk0HFRmn7OzsSZMm/fjjj2QXojVKpRLH8fHjx0dGRuI4XllZSXZFVEd+62n06NEGNO99TExMUFAQ8U9iQy1YsMDR0TgXX9CFli1bRkdHd+jQYdy4ccYx3wPR6x8TE7NlyxbikZoePXoQPZgaTeNnQzRiZHaN//33323btq2srNTKGpB6UFpaOnny5EuXLpFdSLPz7bff0mi09evXk12Ilslksry8PB8fnxMnTty7d2/GjBkUfDKRRKS1ntasWcPj8RBChpJNCKFt27Zt2LChKUfYtWvXw4cPtVdRc7Fhw4bg4OChQ4dmZWWRXYs2mZubE5cOY8eOHTFixOvXrxFCycnJSUlJZJdGCeSMe5JIJCKRiMpDBz60e/duW1vbJk5IQKPR9uzZM2zYMO3V1Vy0bNly1KhRCxYssLCwaNzFNcV5eXkRa3YwGIzTp0/z+XxfX98nT5405w4BfV/cETdcBw4caFjj1tLS0vbv37979+6mH0omk5mamtJ0uWqLcfv9999xHJ81axbZhejD7t27Y2JiiJGABjSqXlv0/UcSFBQUEhJiWNmE4/i+ffu0kk3E0crLy7VyqOZp5syZGIY1k8uf2bNnJyUl0el0Ho83evToxMREsivSK73Gk0KhePDggcHNTDh69Ojvv/9eW0ezsLBYvnx5Wlqatg7YDM2cOfP+/fu//fYb2YXog6WlpYmJiYeHx8aNGwUCAUIoPz///v37ZNelD3qKJxzHd+zYYXDBhBBasmTJvHnztLsw0bp1654+farFAzZDK1asEAqFV65cIbsQ/fH29o6MjCTuJh08eHDTpk1kV6Rzeup7mjBhwsaNG4nJng3I0aNHTU1NIyIiyC4E1KxHjx7Xrl0jfS5zUvB4PC6Xu3XrVo1GM3/+fMPqMKknPbWeYmJiDC6boqOjy8vLdZdNUVFReXl5Ojp4M7F27Vpt9QkaHGKlmQULFtjb25eUlBBDqMguSst03nrKzc2tqKgwuGmb4+LisrKyli1bprtTyOXyadOmxcTE6O4UzUGvXr2SkpKa4V2t96hUqrFjx3bt2vWbb74huxat0W08qdXqbt26GVw33t69e21tbUePHk12IeDjdu3a5eHhMWTIELILoYTU1NQePXpkZGQ4ODg4ODiQXU5T6fbirqioyOBuAMfHx+fn5+stmx4/fmxwHxGl2NnZPXv2jOwqqKJHjx7EDHmTJ0/OzMwku5ym0m08eXh42Nra6vQU2hUbG/vs2bM1a9bo7YwdOnQoKio6cuSI3s5oZDgcjkQiIbsKanF0dLx06ZKZmZlIJLpw4QLZ5TSeDidOPXHiBIvFMqBW9+HDh0tKSpYvX67n806bNk3PZzQmGo3G2tqa7CqoiBgNc+/evWfPnn377bdkl9MYOmw9HTx40IDmrt2wYYNSqSSxWzExMdGgZ18jy5MnT2ANgjqsXr2aeMbTEIfa6Sqe1Gr1mTNn7O3tdXR87Vq6dKmnpye5U1wPGzbsxo0bqampJNZgiMrKyoKCgsiugtKIJRtKS0tXr15Ndi0No6uLO6VSaShPva5ZsyY4OLh///5kF4KIldnz8vK0O0jdiP39998ymaxVq1ZkF2IAgoODMQwjhiAYxHI4Omw9bdu2LSEhQUcH1xaFQhEaGjp8+HAqZFM1kUjUTJ4ma7odO3Z8/vnnZFdhMPr164cQOnXqVGlpKdm11Iuu4okYca+jg2tFbm5unz59Dh482KFDB7Jr+Q8/Pz8zMzNirj5Qh9u3b3t4eMBKTQ01bty4yZMnk11FvVBxnTs9uH79ekxMzP79+8kupFYikejVq1dUi07qUCqV06dPP3z4MNmFGCq1Wk39x/R01Xri8/lyuVxHB2+iffv2Xbp0icrZhBBisVienp6DBw+GSfJrNGrUKOObelyfcByfP38+2VV8hK7iac+ePefPn9fRwZvi+++/VyqVGzduJLuQj7OxsYmOjs7JyRGJRGTXQi2zZs1av369wT1kTikMBmPy5MkUHw+lqw58Nze34uJiHR28cdRq9aJFi4YMGTJgwACya6kv4smp7OzstLQ06AMmTJw4cfv27Qa0ggZlde7cuXPnzmRXUSedrqIXHh4eGhratWtXnZ6lPv7++++goKCcnByyC2mkjRs3pqWlvbdx7ty5JJVDjpKSkrlz5+bl5ZFdiPEgxieSXUWttNx6mjFjxtu3bysrK6VSKYZhxDgL0peaSEpKOnz4sMFNnPCuJUuWvH79msfjWVhYMJlMYuPDhw9jY2PHjRtHdnX6cO3atdjY2C1btlS/fdB0NBotIyMDw7CRI0eSXUsNtNz3tG/fPoVCIZfLaTQakU0IIXL/f1q3bl1WVpYRTKvk6elpa2v7zTfflJWVEc+mK5XKM2fOkF2XPmzdujUpKWnv3r2QTVo3b948yk43qv2u8dDQ0HfnFMdx3M/PT+tnqQ+lUjl+/Pi2bdvOmzePlAK0jk6n//bbbzk5OYMGDSJujBYXFxv36h2FhYVLlixxc3Nr4gKooDa2traDBg0iu4qaaT+evv766/bt21cPp2Kz2d27d9f6WT7q4cOHU6ZMWbly5ahRo/R/dp36+eefqwdtikQiI2gY1iY2Nnbbtm3z588PDw8nuxZjduXKlZKSErKrqIFOBhZs2LChZcuWxNc2Njb6bz3FxcXt2bMnJibmk08+0fOp9YBY6ppAo9HevHmTnJxMakXap1ar582bV1BQsGHDBg8PD7LLMXJXrlx5/vw52VXUQCfxZGVl9d133zk4OOA4bm1tref5LpYsWSIWi3///Xd9nlRvAgMDMew/Y/0lEomRNaBu3LjRrVu3CRMmGNO02VQ2bNgwZ2dnsquoAX3VqlW6OK6LiwuGYY8fPx40aJDe5rsoLi4ODw+fNm1aWFiYfs6ofzY2NlZWVjiOm5iYmJqaKhQKjUYjFotbtWrl6elJdnVaEBUV9fDhw9OnT7u7u5NdS3Ph5eVFzSdkP/LMXVmR/NH1ypJ8mVSkbsTRVWoVg679kZ8O7mYqJe7hY9lloF31xmvXrm3atCk6OppqH/Rff1TmPRPT6VhJvkyLh8Wrh6xpcA2Om5qYaPHgZFFrNAjhdJqWnwWzcTC1ZNP9e1h5toUbf//q3LkzjuNEY7z6v1wulzqT39eVHXnPxbcT+e372LXrbmvBotIEMRiqKJYL+YqDq/ImrfCk07HNmze/ffuWgtMqx/5S4O3P9utpa+dkVj3SAuiZUq7hv5U9vims5Ck79ILh5v8IDAx88OBB9fhEIqFCQkLIrutftbaeXqQJn9+v6h/pqveSGqC8WHb1yFuvvq+Ki4uJ9Z0p5cSvBW272nj7sckuBPwjNaHElsv4NJRDdiGUcOvWrZUrVwoEguotLi4uO3bsoM69iJq7xmUS9fN7VM8mhJCdk3nQIA6twoeC2fQopcLLjw3ZRCk9RjjyipWlBdq8yjZcPXv2rL7DTgxR7NGjB3WyqdZ4epsjozMM40qE62JemNmYfjFdy8uQ2Dqa1mNHoFcWLEbRKynZVVDFxIkTq9e5cXNzo9o/8zXHk5CvdPQ0jFWhrTimbFuGQka5SZEwOmbnZEZ2FeB9Dh7mIgEV/z0jRa9evYiZ2nEc7969u6srtS6Yao4nuUyjUlDuD742ZUVyCk75WVogQ9AXTj0aNRJXqMiugkIiIyOtrKzc3NzGjx9Pdi3vo9L9OADAx+AanF+skAjVkiqVSomrVU39l9kK+XduNYrD4ZTnsstzK5t4NBNTjGFKs2TTLdh0TpOvHiCeADAACoUm6y/Ry4ei0kKZiRmdYcqgm9IZZiYalRYuVDu1jUAIPX+oaPqhGCZ0uVShVqhxHJcJFR4+rE8CmS3bsxp5tKYXBADQqdTz5TlPxDRTE7Y965PeJM+eVn9qpUZYJr59UfjnGV5Qfzv/HlYNPQLEEwDUlXGn6sbpUq6XtXtHw5tYnW5Cs3Vh27qw1Ur107vlaVfLB09xcvZqwNxSEE8AUNQfp3ilRRqfvh40umEsuF0bugndpZ29XKy8fLgsMNi6/s0oiCcAqOjCwRKpjOHYxngGuJsxTbyDXJ7eLcMRal+/hDLsVAbAKJ3bWyyVM7heRvh4oEs7+4y7kruXyuuzM8QTANRyI56nUJlwPY0wmwgu7eyzn8qyHlV9dE+IJwAoJPNRVUmRxijbTe9y83dMu15VUfqRhcQhngCgkJQTZbbuRp5NBLYDO/k4r+59IJ4AoIq0KxXWziyGqZZn46MmNtdSIsILX0rq2AfiCQBKwHH85SORY2u7euxrJBxa2T1MEdaxg9biaer0iMVLvqz/doTQrt1b4s+efHfL2nU/3LlzU1slAS1a/r/Fs2Y3eLYNkUj0MuuFbioyNjlPxThGp+aUqvceJCxZ8alQ+JFrsYaysDIrzZdWVShr24HM1lNubvatW39Uf6tWq9Me3IX/m43JjJnjLl1KILsKw5D1SMzkGMYsRlrE4lrmPBXX9lMy4+lVTtbjJ38Jq/5p3T1//lQoFGRnZ5JYEnXUvUSFoZxRodDCU6bNRFmh3Mqh2a3UwLZnvn5R6+yApI0aFwgqy8v5CKG7d24OGDAEIXTvfipCKCu7mbaeUv5M/nH10jU//nIi7siLF88+Hzd52tQvZTLZvv07r12/rFDI3d08IyIm9vtsAEKooOD15i0//f0ig8226vppz4ULltJoNIRQwrlTJ+OO8nilTk4uwf0GjY2YaGZmplAoDh/Ze/16UmlZCYfDHdB/yJTJs+h0OnHp7e3V0sur5Zn4WLlcFnfiMovFevo0Pfrw78//fooQ6tCh89Qps9u09iGKPBT9e+L502q1um+fkDlfLnp3tfoPjRs/tKKi/GxC3NmEOEdHp9hj5xFCtb2j0tKS/Qd/u3cvVSwWubt7jv98akjwIIRQVnbmwq+/WPFD1N79O/Lz8xwdnCZMmFZezj+XeEokqurYMWjJouU2Nrb6+i3piliokorUdIZOmgsKhexS8q5HT5KUSrk917NvzwkB/v0RQjduH09/mty7++eXkndVVfFcXXzGjPjewd6LeFXRm8yzFzcVFD23YnPtObqa4dfM0iTv71rnViYtnl7lZCGEXF3db976g4inu/duubq6FxUVCASV1tbN4t7qh7Zu/3nGtLnTpn7p5uqh0Wh+WP51cfGbCeOn2tjYpac/WLN2mUwmDR08YuOva/Lz8+bOWSyRiB+lPyCy6VD073Gnjo4KG+fp2aKgIO/EycOFRfnLlq6m0+kPH97r1r23i7Nbdnbm0ZgDbLZVxJh/OpLS0u7I5LKotZslUgmLxUp7cPf7ZQtatmg9e9ZCjUZz584NteqfydteZr0wMzef9cX8rOzMU6eP2dlxJ02cUcd7WbVyw7ffzQvo0HnM6AkmpqYIoTrekUqtevHi2Yjho62tbG7cur4uarmrq3tbH19indEt29YvnL/U1Mxsx85fNmxc7e8fsOKHqJLS4l83rd25a9MP36/Rx+9GlyRVahNzndyw02g0B2IWV1S87dd7Motl9yrn4dGTy+UK6aedhyOE8gsz/kyNGTNimVqtOnXup9gzq+fPOoAQKinL23XgS6alTWj/OXQa42rKfl3UhhBimNHl4lrnhCEtnnJyshgMxvjPp2zfsVEmk1VVCV+9ylr67ar1G1ZlZWcGdv6UrMLIFTZy7MCBQ4mvU/5MfvL00fGYRC7XHiEUEjxIKpWcPnM8dPCI4uI3bVr7DB0ShhAigobHK4s5dmD5D+v69A4mXs7h2G/e8tO8uUus2Fa/7Yyu7nN987bwxs3r1fFEZzBW/BBlYWFBfLtj5y9OTi7btx0gWkYjR4yprs3FxW3zr3vodPqAAUPy83NT/rxadzz5fNKOwWBwOFx//wBiy42b12t7Ry7OrocOxBFFDh48Iiw8JDU1hYgnhNDsWQu7du1JvNmfN/z49YLvvb1b+qEODx/eIxrdhk4iVJmY6SSenj7/Izcvfdnis9ZW9gihTu0HyhWSW3dOEPGEEJo64RcrNgch1LNrROLlrWKJgGlpfSFpO4bRvpq1n8W0RQhhNNqZxA26KA/DMFNzuqRKZcmuIYtIjKdsNzeP3r2Ct2xd/+DB3UpBBYvJCg4etGvPlqysF802njp16lL99d27t1Qq1fjI4dVb1Go1k8lCCPUPCT12/NC27RsmRs6wtbVDCD18eE+lUq2LWr4uajmxM9GXxCsrtWJbVVSUHz6yN+3B3aoqIUKIzfp3/Zi2bf2qs+lt8Zv8/LwZ0+fWeNXGYrKIS0KEkJdXS+Lqr0HqeEcIoexXLw9F78nMfE5sJ679CWam/8y7aGJiihAy+f/y7O0dBIKmTvBIBRo1TjfVyZXd35mpao0qatO/62ZrNGoL83/nhzMz/ee3b2vjjBASCstMGGaZ2Xe7BYUT2YQQotN0GBTmbIZKUXO/J5mtJ2+vliwWKzCw663UFLFY1K17bwaD0cK7VVYzvnlnafHvvZuKCj6Hw930y+53d6AzGAihGdPn2traHY05cOnyuZlfzA8bGcEv5yGEotZtcbD/z3RlLi5u5eX8mbMnWFhYTpv6pYuL24EDvxUUvq7ewcLcovrryopyhNB7R6gRnU5XqRo8Y3cd7+ivR2nfLf2qY0Dgt9+sZFoy/7fqGw3+8dnuiZUjG1oGBVmwGQqJTmZArxLxrdjc2VN3vruRVlPcMOgmRHgJq3hqtcrO1lkX9dRQIV/OtK45iMiJJ41G8zo/t3v3Pgihvr1Ddu7apFQqln2/BiHk3aLV/fu3SamKathsq8rKCkdHZzOz9+dsxjBsdPj4wYNGbN4StW37hlYt27DZ/8xQ4eHh9d7O5xJPV1SU79x+yNHRCSHk4OD0bjy9i2jIlFfwa/xp47wbH3W8oyNH9rm4uEWt28JgMN4LzebAkk1XynSyfoylhZVIXGFr42xiUt+Zv4lGk0hUoYt63qNSqBmmtNqWrSNnYEFRUYFMJvP2bokQ6t69j0QixnE8sHNXhFAL71aFhflica1DIZqPTp26qNXqc4mnqrdIpf/cgpXL5QghJpM5ZcpsotO6Y8cgDMPiz574cGehsNLGxpbIJoSQQFhZW4vD3d3T3t4h6cr56pYRjuMaTePX7LEwt+Dz/x3LV8c7EggrW7VsQ2STQqGQSCVNOa/BsbSiM2100lZo1TJIo1Hfvn+6eotc8ZFl/szNmVyO++Nn11SqWgdMaotKoXbyqnW0lzY/kZKSt4eP7Kv+1tLScnT4+Bq3c7kOCCFvr5YIIeL6zszUzNzcnIgnhNCrVy/bt++oxdoMUf+Q0MTzZ3bv2fq2+E2b1j7Z2S9vpf5x6MApc3PzVau/YzFZgZ273r13CyH0SZu2bq7uo8LGnT5zfNnyr3v26Mvn884mnPwpamub1j4BAYHxZ08eOLjL17fDzZvX791L1Wg0Nd4exTBs5hfz10UtnztvysCBw2g02pWrF8JGRPTvH9q4t+Dv3/Ha9cvHjh9is61827Wv4x0FBAQmJSVevJRgxbaOOx1TVSXMy31lHBdu9cFg0ExMsSqehM3V8sjMzh0G33tw9nzS9orKt67On7wpznr6POXb+SdMTeuaVHfAZzOOnVq5/fcZXToNxWi0m3dO1LFzUwhLJc6utaaQNuOp6E3hwUP/divY2toR8fTh9mFDR5mamrq4uBFb+vYOITogEEKeni0QQllZLyCeTExMNv68c+++7devJ50/f8bNzWP4sNFE+6Ktj1/SlfM3bl7nch0WL/rBz68DQmjunEUODo7x8SfS0u5wONxePT+z5zoghHr36jdp4oz4syfPnj3ZrXvvnTsO/bT+f/FnT0yZPOvDk4YEDzI3Nz98eO+u3ZutrW3atGnr6tb4MS+zZs4vL+cdObrPxtp2zpxFLVq0qu0dTZvyZTmft33HRjbbauiQURGjIzdtiXqU/qD6otXotenEfHZf+/HEYJh8MXnbxSs7Hz25cict3p7j0b3LKDr9I3/4nToMkkqrUlJjzl/Z7mjfwtPdr4xXc4dAE4n54jbDHGr7ac09i/eTyhUy1KGvYTydePznnMkrvMwsqPV48+/LckYt8DIzp1ZVIDdD9CZLNGiKE9mFvE9UoTy3v9TFl3KF6Y5KruLn8MYuqnVpYphrHDSeSCT6fMLQGn80a+YCYlgWqCeWrQnHgVFeWGXnxq5xBxzHV0SF1PxaSxuRpIYBFr4+vT8PX6mtCqUy0bpfR9T4I093/9cFNQw04dq5LfwyurYDluVW+nap6zkeiCfQeJaWlr/vOVbjj6zY1novx+D1HsU9vPZ1bfGEYdiiOUdq/JFKpWQwTD7cbmqqzRugZqaWtRWAcAxhNVyH1TiCgaCQqiQV0vY96xrFAvEEGo9Gozk7Gd76a5RlwaL797IuKRLautbc42ZnS+anTaPRtFiA4I2gT/hH1qGBnhEAKKT7EI6sQiSuqPUpWePAzxfYcbFWHWpuJ1aDeAKAWj7/xj0/vVitMtphX4ISkVoiCR5n/9E9IZ4AoJyZUS1y7xfKREY4W1blWxEuk0Z87VafnSGeAKAcOgOb9qNXSWZpVZlRPT7By6ugqSQjZ9d38ATEEwBURBCvXWoAAAJjSURBVKNhk5d7WprKCh6/lQo+sh4c9QlLxTl3Cz28acNnNuBJY7hzBwB1BY9zKMyS3DjDr7I0NWdbsB0sqblWQm1USnVVqURUJrK2o4XNdbZ1qGt61Q9BPAFAaW6tLcd/Z/nqsSjjTtWzq6W2rky6KcPEjMEwo5uYMaj2WCKGkFKuUsrVaqVGJpDKRErPdsyun3OcvRozAgviCQAD0LIDq2UHFkIo75motEhRVaESC2QaFSap0sk0LI3GtjOhazTWXLo1l+HowXVp0aRxoRBPABgSL1+Wly/ZRehLLZPUmdA0FGs01sHWwaQeEyvqm629Cc2gugmaCToDM2PCHSHDUPPviWlNL39rGDcLZGK1gKc0p97/cBoNEvAN4zNsVipK5BZMnSw6ALSu5r9qjpMprjGM1lNlmdzLl4qLF7q1tqhjdWZAFoVU7eBR32ltAblqjieuqxnLhvH4Rrne62mwm2dKPh1ExXmpug/l3DhVQnYV4D/ynlVVVShb+LHqsS8gX10LXVw/WUajYx362DFMKHfphBASViivHX0TOt2J60zRfwzFQtXxjQUhkS4cJ4pW2HxoNHjWI0HBC/HI2S4YDfoEDcNH1uFJu1KecVvAMKFZ1LRIHlmsOSa5GSK31hZdBtlxXSj9ly8WqG4l8HIyxC3bs4TlOlkpCHwUnYG9yZb49bTuM+rjj6EC6vj4MmEaDS7gKSVCCg2vwGiI42xqZmEwHZxKhYZXJNdQ6CNsXswsaFxXSv8zBmpkJKsYAgCMDxU7lQAAAOIJAEBdEE8AAIqCeAIAUBTEEwCAoiCeAAAU9X+ntOD/xdau/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_graph = StateGraph(CoreState)\n",
    "\n",
    "core_graph.add_node('core_supervisor', core_supervisor_node)\n",
    "core_graph.add_node('research_team', research_graph)\n",
    "core_graph.add_node('LLM', call_llm)\n",
    "core_graph.add_node('router', router)\n",
    "\n",
    "core_graph.add_edge(START, 'core_supervisor')\n",
    "core_graph.add_edge('core_supervisor', 'router')\n",
    "core_graph.add_edge('LLM', 'router')\n",
    "core_graph.add_edge('research_team', 'router')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "core_graph = core_graph.compile(checkpointer=memory)\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(core_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION:  can you give me some papers on SVM \n",
      "\n",
      "((), {'core_supervisor': {'passes': {'research_team': 'Research and provide papers on Support Vector Machines (SVM).'}}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "NEXT WORKER: research_team, TASK: Research and provide papers on Support Vector Machines (SVM).\n",
      "((), {'router': {'call_next': 'research_team', 'current_task': 'Research and provide papers on Support Vector Machines (SVM).', 'passes': {}}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "CURRENT PLAN QUERY: Research and provide papers on Support Vector Machines (SVM).\n",
      "\n",
      "RAG GUIDANCE:  Non-relevant \n",
      "\n",
      "\n",
      " PLAN: Plan: Search for papers on Support Vector Machines (SVM) using the Searcher agent to find relevant publications.\n",
      "#E1 = Searcher[Support Vector Machines papers]\n",
      "\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e',), {'get_plan': {'steps': [('Search for papers on Support Vector Machines (SVM) using the Searcher agent to find relevant publications.', '#E1', 'Searcher', 'Support Vector Machines papers')], 'plan_string': 'Plan: Search for papers on Support Vector Machines (SVM) using the Searcher agent to find relevant publications.\\n#E1 = Searcher[Support Vector Machines papers]', 'task': 'Research and provide papers on Support Vector Machines (SVM).'}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e', 'agent_exec:ad7c52a8-8a8f-25d1-d0e2-d9afb975cab1'), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qqy4', 'function': {'arguments': '{\"query\": \"Support Vector Machine research papers\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 286, 'total_tokens': 308, 'completion_time': 0.08, 'prompt_time': 0.033149618, 'queue_time': 0.022120851000000004, 'total_time': 0.113149618}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_fcc3b74982', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-345fc998-448c-4d16-9e6c-4cd9f03f09b4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Support Vector Machine research papers'}, 'id': 'call_qqy4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 286, 'output_tokens': 22, 'total_tokens': 308})]}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e', 'agent_exec:ad7c52a8-8a8f-25d1-d0e2-d9afb975cab1'), {'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf\", \"content\": \"Abstractâ€”Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT). It is a new hot spot in machine learning research. This article first systematically studies some basic concepts of SVM and the optimization of SVM. In addition, this\"}, {\"url\": \"https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications\", \"content\": \"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"}, {\"url\": \"https://www.researchgate.net/publication/365892847_Support_Vector_Machine\", \"content\": \"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"}]', name='tavily_search_results_json', id='1613a096-6cf1-4662-aca6-8aee6db3d615', tool_call_id='call_qqy4', artifact={'query': 'Support Vector Machine research papers', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'The Development and Application of Support Vector Machine', 'url': 'https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf', 'content': \"Abstractâ€”Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory's(SLT). It is a new hot spot in machine learning research. This article first systematically studies some basic concepts of SVM and the optimization of SVM. In addition, this\", 'score': 0.7065353, 'raw_content': None}, {'title': 'Support Vector Machines: Theory and Applications - ResearchGate', 'url': 'https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications', 'content': 'Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series', 'score': 0.6238588, 'raw_content': None}, {'title': 'Support Vector Machine* - ResearchGate', 'url': 'https://www.researchgate.net/publication/365892847_Support_Vector_Machine', 'content': 'Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.', 'score': 0.6102915, 'raw_content': None}], 'response_time': 2.01})]}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e', 'agent_exec:ad7c52a8-8a8f-25d1-d0e2-d9afb975cab1'), {'agent': {'messages': [AIMessage(content='Here are some papers on SVM:\\n\\n1. \"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\" - https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf\\n2. \"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\" - https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications\\n3. \"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\" - https://www.researchgate.net/publication/365892847_Support_Vector_Machine\\n\\nYou can find more papers on SVM by searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 227, 'prompt_tokens': 559, 'total_tokens': 786, 'completion_time': 0.825454545, 'prompt_time': 0.024796426, 'queue_time': 0.055278044, 'total_time': 0.850250971}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_564b785073', 'finish_reason': 'stop', 'logprobs': None}, id='run-b199c7cc-fd83-4ccc-8f5d-47b6840b4f30-0', usage_metadata={'input_tokens': 559, 'output_tokens': 227, 'total_tokens': 786})]}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "plan: Plan: Search for papers on Support Vector Machines (SVM) using the Searcher agent to find relevant publications.\n",
      "Here are some papers on SVM:\n",
      "\n",
      "1. \"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory's(SLT).\" - https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf\n",
      "2. \"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\" - https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications\n",
      "3. \"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\" - https://www.researchgate.net/publication/365892847_Support_Vector_Machine\n",
      "\n",
      "You can find more papers on SVM by searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore. = Searcher[Support Vector Machines papers]\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e',), {'agent_exec': {'results': {'#E1': 'Here are some papers on SVM:\\n\\n1. \"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\" - https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf\\n2. \"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\" - https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications\\n3. \"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\" - https://www.researchgate.net/publication/365892847_Support_Vector_Machine\\n\\nYou can find more papers on SVM by searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore.'}}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "(('research_team:a7cc3252-c2ed-c340-e6cf-c0ca3f94421e',), {'solve': {'result': 'To address the task of researching and providing papers on Support Vector Machines (SVM), a detailed step-by-step plan was devised. The primary step involved utilizing a Searcher agent to find relevant publications on SVM. Based on the evidence gathered from the Searcher agent\\'s responses, several key papers on SVM were identified.\\n\\n1. **\"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\"** This paper, available at https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf, highlights the foundational aspects and theoretical advantages of SVM, including its roots in Statistical Learning Theory.\\n\\n2. **\"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"** - This publication, found on https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications, not only introduces the development of SVM within the context of statistical learning theory but also underscores its broad applicability across various domains, including time series analysis.\\n\\n3. **\"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"** Available at https://www.researchgate.net/publication/365892847_Support_Vector_Machine, this paper emphasizes the versatility of SVM, showcasing its potential in a wide range of applications such as text categorization, identification tasks, face recognition, and predictive analytics for time series data.\\n\\nIn addition to these specific papers, the Searcher agent suggested searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore for more comprehensive and updated literature on SVM. This approach allows for an exhaustive exploration of the current state of research in SVM, including the latest methodologies, applications, and theoretical advancements.\\n\\nTherefore, to research and provide papers on Support Vector Machines (SVM), it is advisable to:\\n- Consult the referenced papers for foundational knowledge and application insights.\\n- Utilize academic databases like ResearchGate, Google Scholar, and IEEE Xplore for an in-depth exploration of the topic.\\n- Consider the versatility and broad applicability of SVM across different fields and research areas.\\n\\nThis approach will provide a thorough understanding of SVM, its theoretical underpinnings, and its practical applications, thereby fulfilling the task of researching and providing papers on Support Vector Machines.', 'messages': [AIMessage(content='To address the task of researching and providing papers on Support Vector Machines (SVM), a detailed step-by-step plan was devised. The primary step involved utilizing a Searcher agent to find relevant publications on SVM. Based on the evidence gathered from the Searcher agent\\'s responses, several key papers on SVM were identified.\\n\\n1. **\"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\"** This paper, available at https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf, highlights the foundational aspects and theoretical advantages of SVM, including its roots in Statistical Learning Theory.\\n\\n2. **\"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"** - This publication, found on https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications, not only introduces the development of SVM within the context of statistical learning theory but also underscores its broad applicability across various domains, including time series analysis.\\n\\n3. **\"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"** Available at https://www.researchgate.net/publication/365892847_Support_Vector_Machine, this paper emphasizes the versatility of SVM, showcasing its potential in a wide range of applications such as text categorization, identification tasks, face recognition, and predictive analytics for time series data.\\n\\nIn addition to these specific papers, the Searcher agent suggested searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore for more comprehensive and updated literature on SVM. This approach allows for an exhaustive exploration of the current state of research in SVM, including the latest methodologies, applications, and theoretical advancements.\\n\\nTherefore, to research and provide papers on Support Vector Machines (SVM), it is advisable to:\\n- Consult the referenced papers for foundational knowledge and application insights.\\n- Utilize academic databases like ResearchGate, Google Scholar, and IEEE Xplore for an in-depth exploration of the topic.\\n- Consider the versatility and broad applicability of SVM across different fields and research areas.\\n\\nThis approach will provide a thorough understanding of SVM, its theoretical underpinnings, and its practical applications, thereby fulfilling the task of researching and providing papers on Support Vector Machines.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 534, 'prompt_tokens': 434, 'total_tokens': 968, 'completion_time': 2.575633325, 'prompt_time': 0.095854442, 'queue_time': 0.019368405000000005, 'total_time': 2.671487767}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c0cfa69934', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f55d931-2c60-4c24-8acd-dcf50c9377b9-0', usage_metadata={'input_tokens': 434, 'output_tokens': 534, 'total_tokens': 968})], 'results': {}, 'steps': [], 'task': '', 'plan_string': '', 'current_task': ''}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "((), {'research_team': {'messages': [HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}), AIMessage(content='To address the task of researching and providing papers on Support Vector Machines (SVM), a detailed step-by-step plan was devised. The primary step involved utilizing a Searcher agent to find relevant publications on SVM. Based on the evidence gathered from the Searcher agent\\'s responses, several key papers on SVM were identified.\\n\\n1. **\"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\"** This paper, available at https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf, highlights the foundational aspects and theoretical advantages of SVM, including its roots in Statistical Learning Theory.\\n\\n2. **\"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"** - This publication, found on https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications, not only introduces the development of SVM within the context of statistical learning theory but also underscores its broad applicability across various domains, including time series analysis.\\n\\n3. **\"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"** Available at https://www.researchgate.net/publication/365892847_Support_Vector_Machine, this paper emphasizes the versatility of SVM, showcasing its potential in a wide range of applications such as text categorization, identification tasks, face recognition, and predictive analytics for time series data.\\n\\nIn addition to these specific papers, the Searcher agent suggested searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore for more comprehensive and updated literature on SVM. This approach allows for an exhaustive exploration of the current state of research in SVM, including the latest methodologies, applications, and theoretical advancements.\\n\\nTherefore, to research and provide papers on Support Vector Machines (SVM), it is advisable to:\\n- Consult the referenced papers for foundational knowledge and application insights.\\n- Utilize academic databases like ResearchGate, Google Scholar, and IEEE Xplore for an in-depth exploration of the topic.\\n- Consider the versatility and broad applicability of SVM across different fields and research areas.\\n\\nThis approach will provide a thorough understanding of SVM, its theoretical underpinnings, and its practical applications, thereby fulfilling the task of researching and providing papers on Support Vector Machines.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 534, 'prompt_tokens': 434, 'total_tokens': 968, 'completion_time': 2.575633325, 'prompt_time': 0.095854442, 'queue_time': 0.019368405000000005, 'total_time': 2.671487767}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c0cfa69934', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f55d931-2c60-4c24-8acd-dcf50c9377b9-0', usage_metadata={'input_tokens': 434, 'output_tokens': 534, 'total_tokens': 968})], 'current_task': ''}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "((), {'router': {'call_next': '', 'passes': {}, 'current_task': ''}})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "for s in core_graph.stream({'messages': [HumanMessage('can you give me some papers on SVM')]}, config=config, subgraphs=True):\n",
    "  print(s)\n",
    "  print('-'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you give me some papers on SVM', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='To address the task of researching and providing papers on Support Vector Machines (SVM), a detailed step-by-step plan was devised. The primary step involved utilizing a Searcher agent to find relevant publications on SVM. Based on the evidence gathered from the Searcher agent\\'s responses, several key papers on SVM were identified.\\n\\n1. **\"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory\\'s(SLT).\"** This paper, available at https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf, highlights the foundational aspects and theoretical advantages of SVM, including its roots in Statistical Learning Theory.\\n\\n2. **\"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"** - This publication, found on https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications, not only introduces the development of SVM within the context of statistical learning theory but also underscores its broad applicability across various domains, including time series analysis.\\n\\n3. **\"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"** Available at https://www.researchgate.net/publication/365892847_Support_Vector_Machine, this paper emphasizes the versatility of SVM, showcasing its potential in a wide range of applications such as text categorization, identification tasks, face recognition, and predictive analytics for time series data.\\n\\nIn addition to these specific papers, the Searcher agent suggested searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore for more comprehensive and updated literature on SVM. This approach allows for an exhaustive exploration of the current state of research in SVM, including the latest methodologies, applications, and theoretical advancements.\\n\\nTherefore, to research and provide papers on Support Vector Machines (SVM), it is advisable to:\\n- Consult the referenced papers for foundational knowledge and application insights.\\n- Utilize academic databases like ResearchGate, Google Scholar, and IEEE Xplore for an in-depth exploration of the topic.\\n- Consider the versatility and broad applicability of SVM across different fields and research areas.\\n\\nThis approach will provide a thorough understanding of SVM, its theoretical underpinnings, and its practical applications, thereby fulfilling the task of researching and providing papers on Support Vector Machines.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 534, 'prompt_tokens': 434, 'total_tokens': 968, 'completion_time': 2.575633325, 'prompt_time': 0.095854442, 'queue_time': 0.019368405000000005, 'total_time': 2.671487767}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c0cfa69934', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f55d931-2c60-4c24-8acd-dcf50c9377b9-0', usage_metadata={'input_tokens': 434, 'output_tokens': 534, 'total_tokens': 968})],\n",
       " 'passes': {},\n",
       " 'call_next': '',\n",
       " 'current_task': ''}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_graph.get_state(config=config, subgraphs=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you give me some papers on SVM\n",
      "can you give me some papers on SVM\n",
      "can you give me some papers on SVM\n",
      "can you give me some papers on SVM\n",
      "To address the task of researching and providing papers on Support Vector Machines (SVM), a detailed step-by-step plan was devised. The primary step involved utilizing a Searcher agent to find relevant publications on SVM. Based on the evidence gathered from the Searcher agent's responses, several key papers on SVM were identified.\n",
      "\n",
      "1. **\"Support Vector Machine(SVM) algorithm has the advantages of complete theory, global optimization, strong adaptability, and good generalization ability because of it on the basis of Statistical Learning Theory's(SLT).\"** This paper, available at https://iopscience.iop.org/article/10.1088/1742-6596/1748/5/052006/pdf, highlights the foundational aspects and theoretical advantages of SVM, including its roots in Statistical Learning Theory.\n",
      "\n",
      "2. **\"Support Vector Machines (SVM) have been recently developed in the framework of statistical learning theory, and have been successfully applied to a number of applications, ranging from time series\"** - This publication, found on https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications, not only introduces the development of SVM within the context of statistical learning theory but also underscores its broad applicability across various domains, including time series analysis.\n",
      "\n",
      "3. **\"Support vector machines come in various forms and can be used for a variety of applications, including text categorization, practical identification, face recognition, and time series prediction.\"** Available at https://www.researchgate.net/publication/365892847_Support_Vector_Machine, this paper emphasizes the versatility of SVM, showcasing its potential in a wide range of applications such as text categorization, identification tasks, face recognition, and predictive analytics for time series data.\n",
      "\n",
      "In addition to these specific papers, the Searcher agent suggested searching on academic databases such as ResearchGate, Google Scholar, or IEEE Xplore for more comprehensive and updated literature on SVM. This approach allows for an exhaustive exploration of the current state of research in SVM, including the latest methodologies, applications, and theoretical advancements.\n",
      "\n",
      "Therefore, to research and provide papers on Support Vector Machines (SVM), it is advisable to:\n",
      "- Consult the referenced papers for foundational knowledge and application insights.\n",
      "- Utilize academic databases like ResearchGate, Google Scholar, and IEEE Xplore for an in-depth exploration of the topic.\n",
      "- Consider the versatility and broad applicability of SVM across different fields and research areas.\n",
      "\n",
      "This approach will provide a thorough understanding of SVM, its theoretical underpinnings, and its practical applications, thereby fulfilling the task of researching and providing papers on Support Vector Machines.\n"
     ]
    }
   ],
   "source": [
    "for i in core_graph.get_state(config=config, subgraphs=True).values['messages']:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Documentation team -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from tempfile import TemporaryDirectory\n",
    "# from typing import Dict, List, Optional\n",
    "# from langchain_experimental.utilities import PythonREPL\n",
    "# from typing_extensions import Annotated\n",
    "# from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# import logging\n",
    "\n",
    "# # Set up logging\n",
    "# # logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# WORKING_DIRECTORY = Path(\"test_dir\").resolve()\n",
    "# WORKING_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# def validate_file_name(file_name: str) -> bool:\n",
    "#     \"\"\"Validate file name to prevent path traversal attacks.\"\"\"\n",
    "#     safe_path = WORKING_DIRECTORY / file_name\n",
    "#     return safe_path.resolve().parent == WORKING_DIRECTORY.resolve()\n",
    "\n",
    "# @tool\n",
    "# def create_outline(\n",
    "#     points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "#     file_name: Annotated[str, \"File path to save the outline.\"],\n",
    "# ) -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "#     \"\"\"Create and save an outline.\"\"\"\n",
    "#     if not validate_file_name(file_name):\n",
    "#         return \"Error: Invalid file name or path.\"\n",
    "\n",
    "#     try:\n",
    "#         with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "#             for i, point in enumerate(points):\n",
    "#                 file.write(f\"{i + 1}. {point}\\n\")\n",
    "#         logging.info(f\"Outline successfully created: {file_name}\")\n",
    "#         return f\"Outline saved to {file_name}\"\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to create outline: {e}\")\n",
    "#         return f\"Error: Unable to create outline. Details: {e}\"\n",
    "\n",
    "# @tool\n",
    "# def read_document(\n",
    "#     file_name: Annotated[str, \"File path to read the document from.\"],\n",
    "#     start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "#     end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    "# ) -> str:\n",
    "#     \"\"\"Read the specified document.\"\"\"\n",
    "#     if not validate_file_name(file_name):\n",
    "#         return \"Error: Invalid file name or path.\"\n",
    "\n",
    "#     try:\n",
    "#         with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "#             lines = file.readlines()\n",
    "#         start = start or 0\n",
    "#         end = end or len(lines)\n",
    "#         return \"\\n\".join(lines[start:end])\n",
    "#     except FileNotFoundError:\n",
    "#         logging.error(f\"File not found: {file_name}\")\n",
    "#         return \"Error: File not found.\"\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to read document: {e}\")\n",
    "#         return f\"Error: Unable to read document. Details: {e}\"\n",
    "\n",
    "# @tool\n",
    "# def write_document(\n",
    "#     content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "#     file_name: Annotated[str, \"File path to save the document.\"],\n",
    "# ) -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "#     \"\"\"Create and save a text document.\"\"\"\n",
    "#     if not validate_file_name(file_name):\n",
    "#         return \"Error: Invalid file name or path.\"\n",
    "\n",
    "#     try:\n",
    "#         with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "#             file.write(content)\n",
    "#         logging.info(f\"Document successfully written: {file_name}\")\n",
    "#         return f\"Document saved to {file_name}\"\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to write document: {e}\")\n",
    "#         return f\"Error: Unable to write document. Details: {e}\"\n",
    "\n",
    "# @tool\n",
    "# def edit_document(\n",
    "#     file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "#     inserts: Annotated[\n",
    "#         Dict[int, str],\n",
    "#         \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "#     ],\n",
    "# ) -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "#     \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "#     if not validate_file_name(file_name):\n",
    "#         return \"Error: Invalid file name or path.\"\n",
    "\n",
    "#     try:\n",
    "#         with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "#             lines = file.readlines()\n",
    "\n",
    "#         sorted_inserts = sorted(inserts.items())\n",
    "#         for line_number, text in sorted_inserts:\n",
    "#             if 1 <= line_number <= len(lines) + 1:\n",
    "#                 lines.insert(line_number - 1, text + \"\\n\")\n",
    "#             else:\n",
    "#                 return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "#         with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "#             file.writelines(lines)\n",
    "\n",
    "#         logging.info(f\"Document successfully edited: {file_name}\")\n",
    "#         return f\"Document edited and saved to {file_name}\"\n",
    "#     except FileNotFoundError:\n",
    "#         logging.error(f\"File not found: {file_name}\")\n",
    "#         return \"Error: File not found.\"\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to edit document: {e}\")\n",
    "#         return f\"Error: Unable to edit document. Details: {e}\"\n",
    "\n",
    "# repl = PythonREPL()\n",
    "\n",
    "# @tool\n",
    "# def python_repl_tool(\n",
    "#     code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "# ):\n",
    "#     \"\"\"Execute Python code and return the output.\"\"\"\n",
    "#     try:\n",
    "#         result = repl.run(code)\n",
    "#         logging.info(\"Python code executed successfully.\")\n",
    "#         return f\"Successfully executed:\\n```\\n{code}\\n```\\nStdout: {result}\"\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Python code execution failed: {e}\")\n",
    "#         return f\"Failed to execute. Error: {repr(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_writer_agent = create_react_agent(\n",
    "#     llm,\n",
    "#     tools=[write_document, edit_document, read_document],\n",
    "#     state_modifier=(\n",
    "#         \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "#         \"Don't ask follow-up questions.\"\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "# def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "#     result = doc_writer_agent.invoke(state)\n",
    "#     return Command(\n",
    "#         update={\n",
    "#             \"messages\": [\n",
    "#                 HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "#             ]\n",
    "#         },\n",
    "#         # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "#         goto=\"supervisor\",\n",
    "#     )\n",
    "\n",
    "\n",
    "# note_taking_agent = create_react_agent(\n",
    "#     llm,\n",
    "#     tools=[create_outline, read_document],\n",
    "#     state_modifier=(\n",
    "#         \"You can read documents and create outlines for the document writer. \"\n",
    "#         \"Don't ask follow-up questions.\"\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "# def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "#     result = note_taking_agent.invoke(state)\n",
    "#     return Command(\n",
    "#         update={\n",
    "#             \"messages\": [\n",
    "#                 HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "#             ]\n",
    "#         },\n",
    "#         # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "#         goto=\"supervisor\",\n",
    "#     )\n",
    "\n",
    "\n",
    "# chart_generating_agent = create_react_agent(\n",
    "#     llm, tools=[read_document, python_repl_tool]\n",
    "# )\n",
    "\n",
    "\n",
    "# def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "#     result = chart_generating_agent.invoke(state)\n",
    "#     return Command(\n",
    "#         update={\n",
    "#             \"messages\": [\n",
    "#                 HumanMessage(\n",
    "#                     content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "#                 )\n",
    "#             ]\n",
    "#         },\n",
    "#         # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "#         goto=\"supervisor\",\n",
    "#     )\n",
    "\n",
    "\n",
    "# doc_writing_supervisor_node = make_supervisor_node(\n",
    "#     llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'supervisor_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gp \u001b[38;5;241m=\u001b[39m StateGraph(CoreState)\n\u001b[0;32m----> 2\u001b[0m gp\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupervisor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43msupervisor_node\u001b[49m)\n\u001b[1;32m      4\u001b[0m gp\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m gp \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mcompile()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'supervisor_node' is not defined"
     ]
    }
   ],
   "source": [
    "gp = StateGraph(CoreState)\n",
    "gp.add_node('supervisor', supervisor_node)\n",
    "\n",
    "gp.add_edge(START, \"supervisor\")\n",
    "gp = gp.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
